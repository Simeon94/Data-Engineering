{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.1 64-bit ('base': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "interpreter": {
      "hash": "ad8bebc098a042dc0df4e42fc2ecc8fff0bd7b8741641ce29007c29766dadbe0"
    },
    "colab": {
      "name": "Notebook.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--CjDQ3lW5px"
      },
      "source": [
        "# Data Cleaning\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Identify what dirty data is\n",
        "- The side effects of working with dirty data\n",
        "- How to clean data\n",
        "\n",
        "A critical step before we run our data through the model is **Exploratory Data Analysis**, or EDA. EDA, as the name suggests, is an indepth analysis of our data. The EDA process intertwines data cleaning, dealing with missing values, and visualising data and its statistical properties. Typically these processes are all done together, but for the sake of clarifying the different concepts we will introduce them here separately. I will be providing toy examples through screenshots, while you guys will be trying to apply the concepts to a messy dataset!\n",
        "\n",
        "\n",
        "## Prerequisites\n",
        "[flights.txt](https://drive.google.com/file/d/1cVV3TZcxS31fk9JrskaRP1pbOfaoNcwe/view?usp=sharing)\n",
        "(source: https://www.kaggle.com/mmetter/flights/data).\n",
        "In most cases you will receive data which has documentation. **Reading data documentation is important**!!!! This particular piece of data doesn't have any documentation however - we'll have to use our intuition regarding the column/variable names\n",
        "\n",
        "## Data types\n",
        "Before we get started, let's talk about some different data types we can expect to come across:\n",
        "<p align=center>\n",
        "\t<table >\n",
        "\t\t<tbody>\n",
        "\t\t\t<tr>\n",
        "\t\t\t\t<td><b>Data type</b></td>\n",
        "\t\t\t\t<td><b>Python data type</b></td>\n",
        "\t\t\t\t<td><b>Examples</b></td>\n",
        "\t\t\t</tr>\n",
        "\t\t\t<tr>\n",
        "\t\t\t\t<td>Text data</td>\n",
        "\t\t\t\t<td>str</td>\n",
        "\t\t\t\t<td>Names, addresses</td>\n",
        "\t\t\t</tr>\n",
        "\t\t\t<tr>\n",
        "\t\t\t\t<td>Integers</td>\n",
        "\t\t\t\t<td>int</td>\n",
        "\t\t\t\t<td># items, # people</td>\n",
        "\t\t\t</tr>\n",
        "\t\t\t<tr>\n",
        "\t\t\t\t<td>Floats/Decimals</td>\n",
        "\t\t\t\t<td>float</td>\n",
        "\t\t\t\t<td>Currency, distances</td>\n",
        "\t\t\t</tr>\n",
        "\t\t\t<tr>\n",
        "\t\t\t\t<td>Binary/Boolean</td>\n",
        "\t\t\t\t<td>bool</td>\n",
        "\t\t\t\t<td>Is married, yes/no</td>\n",
        "\t\t\t</tr>\n",
        "\t\t\t<tr>\n",
        "\t\t\t\t<td>Date (and times)</td>\n",
        "\t\t\t\t<td>datetime</td>\n",
        "\t\t\t\t<td>Dispatch date, arrival time</td>\n",
        "\t\t\t</tr>\n",
        "\t\t\t<tr>\n",
        "\t\t\t\t<td>Categories</td>\n",
        "\t\t\t\t<td>category</td>\n",
        "\t\t\t\t<td>States, colours, gender</td>\n",
        "\t\t\t</tr>\n",
        "\t\t</tbody>\n",
        "\t</table>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wS7r6QoXEya",
        "outputId": "b908f35a-dd35-4eed-e02b-96823f3b27d9"
      },
      "source": [
        "!wget https://aicoreassessments.s3.amazonaws.com/flights.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-11 04:08:58--  https://aicoreassessments.s3.amazonaws.com/flights.txt\n",
            "Resolving aicoreassessments.s3.amazonaws.com (aicoreassessments.s3.amazonaws.com)... 52.217.102.92\n",
            "Connecting to aicoreassessments.s3.amazonaws.com (aicoreassessments.s3.amazonaws.com)|52.217.102.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 314586167 (300M) [text/plain]\n",
            "Saving to: ‘flights.txt’\n",
            "\n",
            "flights.txt         100%[===================>] 300.01M  37.1MB/s    in 7.9s    \n",
            "\n",
            "2021-10-11 04:09:06 (37.9 MB/s) - ‘flights.txt’ saved [314586167/314586167]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWj1YqoqW5p5"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "flights_df = pd.read_csv(\"/flights.txt\", sep=\"|\") # Make sure flights.txt is in the same directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5RwZdPwXhZK"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "flights_df = pd.read_csv(\"flights.txt\", sep=\"|\") # Make sure flights.txt is in the same directory"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "kLUVnF6_W5p7",
        "outputId": "0276037a-eded-415b-acf4-69613dca4882"
      },
      "source": [
        "flights_df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TRANSACTIONID</th>\n",
              "      <th>FLIGHTDATE</th>\n",
              "      <th>AIRLINECODE</th>\n",
              "      <th>AIRLINENAME</th>\n",
              "      <th>TAILNUM</th>\n",
              "      <th>FLIGHTNUM</th>\n",
              "      <th>ORIGINAIRPORTCODE</th>\n",
              "      <th>ORIGAIRPORTNAME</th>\n",
              "      <th>ORIGINCITYNAME</th>\n",
              "      <th>ORIGINSTATE</th>\n",
              "      <th>ORIGINSTATENAME</th>\n",
              "      <th>DESTAIRPORTCODE</th>\n",
              "      <th>DESTAIRPORTNAME</th>\n",
              "      <th>DESTCITYNAME</th>\n",
              "      <th>DESTSTATE</th>\n",
              "      <th>DESTSTATENAME</th>\n",
              "      <th>CRSDEPTIME</th>\n",
              "      <th>DEPTIME</th>\n",
              "      <th>DEPDELAY</th>\n",
              "      <th>TAXIOUT</th>\n",
              "      <th>WHEELSOFF</th>\n",
              "      <th>WHEELSON</th>\n",
              "      <th>TAXIIN</th>\n",
              "      <th>CRSARRTIME</th>\n",
              "      <th>ARRTIME</th>\n",
              "      <th>ARRDELAY</th>\n",
              "      <th>CRSELAPSEDTIME</th>\n",
              "      <th>ACTUALELAPSEDTIME</th>\n",
              "      <th>CANCELLED</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>DISTANCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>54548800</td>\n",
              "      <td>20020101</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.: WN</td>\n",
              "      <td>N103@@</td>\n",
              "      <td>1425</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>DAL</td>\n",
              "      <td>DallasTX: Dallas Love Field</td>\n",
              "      <td>Dallas</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>1425</td>\n",
              "      <td>1425.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1433.0</td>\n",
              "      <td>1648.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1655</td>\n",
              "      <td>1652.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>580 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55872300</td>\n",
              "      <td>20020101</td>\n",
              "      <td>CO</td>\n",
              "      <td>Continental Air Lines Inc.: CO</td>\n",
              "      <td>N83872</td>\n",
              "      <td>150</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>IAH</td>\n",
              "      <td>HoustonTX: George Bush Intercontinental/Houston</td>\n",
              "      <td>Houston</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>1130</td>\n",
              "      <td>1136.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1148.0</td>\n",
              "      <td>1419.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1426</td>\n",
              "      <td>1435.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>False</td>\n",
              "      <td>F</td>\n",
              "      <td>744 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54388800</td>\n",
              "      <td>20020101</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.: WN</td>\n",
              "      <td>N334@@</td>\n",
              "      <td>249</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>MCI</td>\n",
              "      <td>Kansas CityMO: Kansas City International</td>\n",
              "      <td>Kansas City</td>\n",
              "      <td>MO</td>\n",
              "      <td>Missouri</td>\n",
              "      <td>1215</td>\n",
              "      <td>1338.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1345.0</td>\n",
              "      <td>1618.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1500</td>\n",
              "      <td>1620.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>718 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54486500</td>\n",
              "      <td>20020101</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.: WN</td>\n",
              "      <td>N699@@</td>\n",
              "      <td>902</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>LAS</td>\n",
              "      <td>Las VegasNV: McCarran International</td>\n",
              "      <td>Las Vegas</td>\n",
              "      <td>NV</td>\n",
              "      <td>Nevada</td>\n",
              "      <td>1925</td>\n",
              "      <td>1925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1930.0</td>\n",
              "      <td>1947.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1950</td>\n",
              "      <td>1948.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>487 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55878700</td>\n",
              "      <td>20020103</td>\n",
              "      <td>CO</td>\n",
              "      <td>Continental Air Lines Inc.: CO</td>\n",
              "      <td>N58606</td>\n",
              "      <td>234</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>IAH</td>\n",
              "      <td>HoustonTX: George Bush Intercontinental/Houston</td>\n",
              "      <td>Houston</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>1455</td>\n",
              "      <td>1453.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1504.0</td>\n",
              "      <td>1742.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1750</td>\n",
              "      <td>1747.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>744 miles</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TRANSACTIONID  FLIGHTDATE AIRLINECODE                     AIRLINENAME  \\\n",
              "0       54548800    20020101          WN      Southwest Airlines Co.: WN   \n",
              "1       55872300    20020101          CO  Continental Air Lines Inc.: CO   \n",
              "2       54388800    20020101          WN      Southwest Airlines Co.: WN   \n",
              "3       54486500    20020101          WN      Southwest Airlines Co.: WN   \n",
              "4       55878700    20020103          CO  Continental Air Lines Inc.: CO   \n",
              "\n",
              "  TAILNUM  FLIGHTNUM ORIGINAIRPORTCODE  \\\n",
              "0  N103@@       1425               ABQ   \n",
              "1  N83872        150               ABQ   \n",
              "2  N334@@        249               ABQ   \n",
              "3  N699@@        902               ABQ   \n",
              "4  N58606        234               ABQ   \n",
              "\n",
              "                                    ORIGAIRPORTNAME ORIGINCITYNAME  \\\n",
              "0  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "1  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "2  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "3  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "4  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "\n",
              "  ORIGINSTATE ORIGINSTATENAME DESTAIRPORTCODE  \\\n",
              "0          NM      New Mexico             DAL   \n",
              "1          NM      New Mexico             IAH   \n",
              "2          NM      New Mexico             MCI   \n",
              "3          NM      New Mexico             LAS   \n",
              "4          NM      New Mexico             IAH   \n",
              "\n",
              "                                   DESTAIRPORTNAME DESTCITYNAME DESTSTATE  \\\n",
              "0                      DallasTX: Dallas Love Field       Dallas        TX   \n",
              "1  HoustonTX: George Bush Intercontinental/Houston      Houston        TX   \n",
              "2         Kansas CityMO: Kansas City International  Kansas City        MO   \n",
              "3              Las VegasNV: McCarran International    Las Vegas        NV   \n",
              "4  HoustonTX: George Bush Intercontinental/Houston      Houston        TX   \n",
              "\n",
              "  DESTSTATENAME  CRSDEPTIME  DEPTIME  DEPDELAY  TAXIOUT  WHEELSOFF  WHEELSON  \\\n",
              "0         Texas        1425   1425.0       0.0      8.0     1433.0    1648.0   \n",
              "1         Texas        1130   1136.0       6.0     12.0     1148.0    1419.0   \n",
              "2      Missouri        1215   1338.0      83.0      7.0     1345.0    1618.0   \n",
              "3        Nevada        1925   1925.0       0.0      5.0     1930.0    1947.0   \n",
              "4         Texas        1455   1453.0      -2.0     11.0     1504.0    1742.0   \n",
              "\n",
              "   TAXIIN  CRSARRTIME  ARRTIME  ARRDELAY  CRSELAPSEDTIME  ACTUALELAPSEDTIME  \\\n",
              "0     4.0        1655   1652.0      -3.0            90.0               87.0   \n",
              "1    16.0        1426   1435.0       9.0           116.0              119.0   \n",
              "2     2.0        1500   1620.0      80.0           105.0              102.0   \n",
              "3     1.0        1950   1948.0      -2.0            85.0               83.0   \n",
              "4     5.0        1750   1747.0      -3.0           115.0              114.0   \n",
              "\n",
              "  CANCELLED DIVERTED   DISTANCE  \n",
              "0         F    False  580 miles  \n",
              "1     False        F  744 miles  \n",
              "2         F    False  718 miles  \n",
              "3         0        0  487 miles  \n",
              "4         F    False  744 miles  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLg1Jv1xW5p8"
      },
      "source": [
        "There are many issues that I can see with the data. We'll tackle them in an arbitrary order one by one, but lets first try and decide what we think each of the non-trivial columns is meant to represent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59VoidC9W5p8"
      },
      "source": [
        "- **TRANSACTIONID**: Unique identifer\n",
        "\n",
        "- **FLIGHTDATE**: Date of the flight. Looks like its encoded as a number instead of a date object\n",
        "\n",
        "- **TAILNUM**: Looks like it contains @@ in some of its rows. \n",
        "\n",
        "- **ORIGAIRPORTNAME** and **DESTAIRPORTNAME**: Looks like it has the city name and state concatenated and appended before the actual name of the airport \n",
        "\n",
        "- **CRSDEPTIME** and **DEPTIME**: Look like they represent incorrectly formatted (military) times. Also it seems to be that **CRSDEPTTIME** + **DEPDELAY** = **DEPTIME**\n",
        "\n",
        "- **DEPDELAY**: Departure delay in minutes?\n",
        "\n",
        "- **TAXIOUT**: How long it took from departure to wheels off. Looks like **DEPTIME** + **TAXIOUT** = **WHEELSOFF**\n",
        "\n",
        "- **WHEELSOFF**: The (military) time when wheels left the ground\n",
        "\n",
        "- **WHEELSON**: Military time when wheels touched the ground on descent\n",
        "\n",
        "- **TAXIIN**: Looks like the number of minutes since the wheels touched the ground to \"parking\"\n",
        "\n",
        "- **CRSARRTIME**: The military encoded expected arrival time\n",
        "\n",
        "- **ARRTIME**: Actual arrival time\n",
        "\n",
        "- **ARRDELAY**: Difference between **CRSARRTIME** and **ARRTIME**\n",
        "\n",
        "- **CRSELAPSEDTIME**: Planned journey time (minutes)\n",
        "\n",
        "- **ACTUALELAPSEDTIME**: Actual journey time (minutes)\n",
        "\n",
        "- **CANCELLED**: Whether the flight was cancelled or not. Looks like some values are False, others are F, and others 0. Possibly a similar variation for True\n",
        "\n",
        "- **DIVERTED**: Whether the plane was diverted. Similar issues regarding True/False as above?\n",
        "\n",
        "- **DISTANCE**: The (integer) distance the plane travelled, encoded as a string with \"miles\" concatenated to it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "3nxpjypdW5p9",
        "outputId": "6e009861-54f3-4c66-86f9-72c5a7a92b3b"
      },
      "source": [
        "flights_df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TRANSACTIONID</th>\n",
              "      <th>FLIGHTDATE</th>\n",
              "      <th>AIRLINECODE</th>\n",
              "      <th>AIRLINENAME</th>\n",
              "      <th>TAILNUM</th>\n",
              "      <th>FLIGHTNUM</th>\n",
              "      <th>ORIGINAIRPORTCODE</th>\n",
              "      <th>ORIGAIRPORTNAME</th>\n",
              "      <th>ORIGINCITYNAME</th>\n",
              "      <th>ORIGINSTATE</th>\n",
              "      <th>ORIGINSTATENAME</th>\n",
              "      <th>DESTAIRPORTCODE</th>\n",
              "      <th>DESTAIRPORTNAME</th>\n",
              "      <th>DESTCITYNAME</th>\n",
              "      <th>DESTSTATE</th>\n",
              "      <th>DESTSTATENAME</th>\n",
              "      <th>CRSDEPTIME</th>\n",
              "      <th>DEPTIME</th>\n",
              "      <th>DEPDELAY</th>\n",
              "      <th>TAXIOUT</th>\n",
              "      <th>WHEELSOFF</th>\n",
              "      <th>WHEELSON</th>\n",
              "      <th>TAXIIN</th>\n",
              "      <th>CRSARRTIME</th>\n",
              "      <th>ARRTIME</th>\n",
              "      <th>ARRDELAY</th>\n",
              "      <th>CRSELAPSEDTIME</th>\n",
              "      <th>ACTUALELAPSEDTIME</th>\n",
              "      <th>CANCELLED</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>DISTANCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>54548800</td>\n",
              "      <td>20020101</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.: WN</td>\n",
              "      <td>N103@@</td>\n",
              "      <td>1425</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>DAL</td>\n",
              "      <td>DallasTX: Dallas Love Field</td>\n",
              "      <td>Dallas</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>1425</td>\n",
              "      <td>1425.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1433.0</td>\n",
              "      <td>1648.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1655</td>\n",
              "      <td>1652.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>580 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55872300</td>\n",
              "      <td>20020101</td>\n",
              "      <td>CO</td>\n",
              "      <td>Continental Air Lines Inc.: CO</td>\n",
              "      <td>N83872</td>\n",
              "      <td>150</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>IAH</td>\n",
              "      <td>HoustonTX: George Bush Intercontinental/Houston</td>\n",
              "      <td>Houston</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>1130</td>\n",
              "      <td>1136.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1148.0</td>\n",
              "      <td>1419.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1426</td>\n",
              "      <td>1435.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>116.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>False</td>\n",
              "      <td>F</td>\n",
              "      <td>744 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54388800</td>\n",
              "      <td>20020101</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.: WN</td>\n",
              "      <td>N334@@</td>\n",
              "      <td>249</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>MCI</td>\n",
              "      <td>Kansas CityMO: Kansas City International</td>\n",
              "      <td>Kansas City</td>\n",
              "      <td>MO</td>\n",
              "      <td>Missouri</td>\n",
              "      <td>1215</td>\n",
              "      <td>1338.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1345.0</td>\n",
              "      <td>1618.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1500</td>\n",
              "      <td>1620.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>718 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54486500</td>\n",
              "      <td>20020101</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.: WN</td>\n",
              "      <td>N699@@</td>\n",
              "      <td>902</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>LAS</td>\n",
              "      <td>Las VegasNV: McCarran International</td>\n",
              "      <td>Las Vegas</td>\n",
              "      <td>NV</td>\n",
              "      <td>Nevada</td>\n",
              "      <td>1925</td>\n",
              "      <td>1925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1930.0</td>\n",
              "      <td>1947.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1950</td>\n",
              "      <td>1948.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>487 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55878700</td>\n",
              "      <td>20020103</td>\n",
              "      <td>CO</td>\n",
              "      <td>Continental Air Lines Inc.: CO</td>\n",
              "      <td>N58606</td>\n",
              "      <td>234</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>IAH</td>\n",
              "      <td>HoustonTX: George Bush Intercontinental/Houston</td>\n",
              "      <td>Houston</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>1455</td>\n",
              "      <td>1453.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1504.0</td>\n",
              "      <td>1742.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1750</td>\n",
              "      <td>1747.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>744 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1191800</th>\n",
              "      <td>126750200</td>\n",
              "      <td>20130106</td>\n",
              "      <td>EV</td>\n",
              "      <td>ExpressJet Airlines Inc.: EV</td>\n",
              "      <td>N683BR</td>\n",
              "      <td>5272</td>\n",
              "      <td>ATL</td>\n",
              "      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>GA</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>DAL</td>\n",
              "      <td>DallasTX: Dallas Love Field</td>\n",
              "      <td>Dallas</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>1357</td>\n",
              "      <td>1348.0</td>\n",
              "      <td>-9.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1410.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1523</td>\n",
              "      <td>1503.0</td>\n",
              "      <td>-20.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>721 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1191801</th>\n",
              "      <td>127294500</td>\n",
              "      <td>20130106</td>\n",
              "      <td>DL</td>\n",
              "      <td>Delta Air Lines Inc.: DL</td>\n",
              "      <td>N949DL</td>\n",
              "      <td>1711</td>\n",
              "      <td>ATL</td>\n",
              "      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>GA</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>DFW</td>\n",
              "      <td>Dallas/Fort WorthTX: Dallas/Fort Worth Interna...</td>\n",
              "      <td>Dallas/Fort Worth</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>2150</td>\n",
              "      <td>2147.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2210.0</td>\n",
              "      <td>2307.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2321</td>\n",
              "      <td>2317.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>False</td>\n",
              "      <td>F</td>\n",
              "      <td>731 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1191802</th>\n",
              "      <td>127294900</td>\n",
              "      <td>20130106</td>\n",
              "      <td>DL</td>\n",
              "      <td>Delta Air Lines Inc.: DL</td>\n",
              "      <td>N907DE</td>\n",
              "      <td>1810</td>\n",
              "      <td>ATL</td>\n",
              "      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>GA</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>DFW</td>\n",
              "      <td>Dallas/Fort WorthTX: Dallas/Fort Worth Interna...</td>\n",
              "      <td>Dallas/Fort Worth</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>1617</td>\n",
              "      <td>1617.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1635.0</td>\n",
              "      <td>1728.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1750</td>\n",
              "      <td>1737.0</td>\n",
              "      <td>-13.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>731 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1191803</th>\n",
              "      <td>126594900</td>\n",
              "      <td>20130106</td>\n",
              "      <td>EV</td>\n",
              "      <td>ExpressJet Airlines Inc.: EV</td>\n",
              "      <td>N855AS</td>\n",
              "      <td>5208</td>\n",
              "      <td>ATL</td>\n",
              "      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>GA</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>FWA</td>\n",
              "      <td>Fort WayneIN: Fort Wayne International</td>\n",
              "      <td>Fort Wayne</td>\n",
              "      <td>IN</td>\n",
              "      <td>Indiana</td>\n",
              "      <td>1516</td>\n",
              "      <td>1514.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1535.0</td>\n",
              "      <td>1651.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1658</td>\n",
              "      <td>1655.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>False</td>\n",
              "      <td>F</td>\n",
              "      <td>508 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1191804</th>\n",
              "      <td>126620300</td>\n",
              "      <td>20130106</td>\n",
              "      <td>EV</td>\n",
              "      <td>ExpressJet Airlines Inc.: EV</td>\n",
              "      <td>N138EV</td>\n",
              "      <td>5549</td>\n",
              "      <td>ATL</td>\n",
              "      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>GA</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>GSO</td>\n",
              "      <td>Greensboro/High PointNC: Piedmont Triad Intern...</td>\n",
              "      <td>Greensboro/High Point</td>\n",
              "      <td>NC</td>\n",
              "      <td>North Carolina</td>\n",
              "      <td>1452</td>\n",
              "      <td>1458.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1525.0</td>\n",
              "      <td>1611.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1609</td>\n",
              "      <td>1615.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>306 miles</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1191805 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         TRANSACTIONID  FLIGHTDATE AIRLINECODE  \\\n",
              "0             54548800    20020101          WN   \n",
              "1             55872300    20020101          CO   \n",
              "2             54388800    20020101          WN   \n",
              "3             54486500    20020101          WN   \n",
              "4             55878700    20020103          CO   \n",
              "...                ...         ...         ...   \n",
              "1191800      126750200    20130106          EV   \n",
              "1191801      127294500    20130106          DL   \n",
              "1191802      127294900    20130106          DL   \n",
              "1191803      126594900    20130106          EV   \n",
              "1191804      126620300    20130106          EV   \n",
              "\n",
              "                            AIRLINENAME TAILNUM  FLIGHTNUM ORIGINAIRPORTCODE  \\\n",
              "0            Southwest Airlines Co.: WN  N103@@       1425               ABQ   \n",
              "1        Continental Air Lines Inc.: CO  N83872        150               ABQ   \n",
              "2            Southwest Airlines Co.: WN  N334@@        249               ABQ   \n",
              "3            Southwest Airlines Co.: WN  N699@@        902               ABQ   \n",
              "4        Continental Air Lines Inc.: CO  N58606        234               ABQ   \n",
              "...                                 ...     ...        ...               ...   \n",
              "1191800    ExpressJet Airlines Inc.: EV  N683BR       5272               ATL   \n",
              "1191801        Delta Air Lines Inc.: DL  N949DL       1711               ATL   \n",
              "1191802        Delta Air Lines Inc.: DL  N907DE       1810               ATL   \n",
              "1191803    ExpressJet Airlines Inc.: EV  N855AS       5208               ATL   \n",
              "1191804    ExpressJet Airlines Inc.: EV  N138EV       5549               ATL   \n",
              "\n",
              "                                           ORIGAIRPORTNAME ORIGINCITYNAME  \\\n",
              "0         AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "1         AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "2         AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "3         AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "4         AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "...                                                    ...            ...   \n",
              "1191800  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n",
              "1191801  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n",
              "1191802  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n",
              "1191803  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n",
              "1191804  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n",
              "\n",
              "        ORIGINSTATE ORIGINSTATENAME DESTAIRPORTCODE  \\\n",
              "0                NM      New Mexico             DAL   \n",
              "1                NM      New Mexico             IAH   \n",
              "2                NM      New Mexico             MCI   \n",
              "3                NM      New Mexico             LAS   \n",
              "4                NM      New Mexico             IAH   \n",
              "...             ...             ...             ...   \n",
              "1191800          GA         Georgia             DAL   \n",
              "1191801          GA         Georgia             DFW   \n",
              "1191802          GA         Georgia             DFW   \n",
              "1191803          GA         Georgia             FWA   \n",
              "1191804          GA         Georgia             GSO   \n",
              "\n",
              "                                           DESTAIRPORTNAME  \\\n",
              "0                              DallasTX: Dallas Love Field   \n",
              "1          HoustonTX: George Bush Intercontinental/Houston   \n",
              "2                 Kansas CityMO: Kansas City International   \n",
              "3                      Las VegasNV: McCarran International   \n",
              "4          HoustonTX: George Bush Intercontinental/Houston   \n",
              "...                                                    ...   \n",
              "1191800                        DallasTX: Dallas Love Field   \n",
              "1191801  Dallas/Fort WorthTX: Dallas/Fort Worth Interna...   \n",
              "1191802  Dallas/Fort WorthTX: Dallas/Fort Worth Interna...   \n",
              "1191803             Fort WayneIN: Fort Wayne International   \n",
              "1191804  Greensboro/High PointNC: Piedmont Triad Intern...   \n",
              "\n",
              "                  DESTCITYNAME DESTSTATE   DESTSTATENAME  CRSDEPTIME  DEPTIME  \\\n",
              "0                       Dallas        TX           Texas        1425   1425.0   \n",
              "1                      Houston        TX           Texas        1130   1136.0   \n",
              "2                  Kansas City        MO        Missouri        1215   1338.0   \n",
              "3                    Las Vegas        NV          Nevada        1925   1925.0   \n",
              "4                      Houston        TX           Texas        1455   1453.0   \n",
              "...                        ...       ...             ...         ...      ...   \n",
              "1191800                 Dallas        TX           Texas        1357   1348.0   \n",
              "1191801      Dallas/Fort Worth        TX           Texas        2150   2147.0   \n",
              "1191802      Dallas/Fort Worth        TX           Texas        1617   1617.0   \n",
              "1191803             Fort Wayne        IN         Indiana        1516   1514.0   \n",
              "1191804  Greensboro/High Point        NC  North Carolina        1452   1458.0   \n",
              "\n",
              "         DEPDELAY  TAXIOUT  WHEELSOFF  WHEELSON  TAXIIN  CRSARRTIME  ARRTIME  \\\n",
              "0             0.0      8.0     1433.0    1648.0     4.0        1655   1652.0   \n",
              "1             6.0     12.0     1148.0    1419.0    16.0        1426   1435.0   \n",
              "2            83.0      7.0     1345.0    1618.0     2.0        1500   1620.0   \n",
              "3             0.0      5.0     1930.0    1947.0     1.0        1950   1948.0   \n",
              "4            -2.0     11.0     1504.0    1742.0     5.0        1750   1747.0   \n",
              "...           ...      ...        ...       ...     ...         ...      ...   \n",
              "1191800      -9.0     22.0     1410.0    1500.0     3.0        1523   1503.0   \n",
              "1191801      -3.0     23.0     2210.0    2307.0    10.0        2321   2317.0   \n",
              "1191802       0.0     18.0     1635.0    1728.0     9.0        1750   1737.0   \n",
              "1191803      -2.0     21.0     1535.0    1651.0     4.0        1658   1655.0   \n",
              "1191804       6.0     27.0     1525.0    1611.0     4.0        1609   1615.0   \n",
              "\n",
              "         ARRDELAY  CRSELAPSEDTIME  ACTUALELAPSEDTIME CANCELLED DIVERTED  \\\n",
              "0            -3.0            90.0               87.0         F    False   \n",
              "1             9.0           116.0              119.0     False        F   \n",
              "2            80.0           105.0              102.0         F    False   \n",
              "3            -2.0            85.0               83.0         0        0   \n",
              "4            -3.0           115.0              114.0         F    False   \n",
              "...           ...             ...                ...       ...      ...   \n",
              "1191800     -20.0           146.0              135.0         0        0   \n",
              "1191801      -4.0           151.0              150.0     False        F   \n",
              "1191802     -13.0           153.0              140.0         F    False   \n",
              "1191803      -3.0           102.0              101.0     False        F   \n",
              "1191804       6.0            77.0               77.0     False    False   \n",
              "\n",
              "          DISTANCE  \n",
              "0        580 miles  \n",
              "1        744 miles  \n",
              "2        718 miles  \n",
              "3        487 miles  \n",
              "4        744 miles  \n",
              "...            ...  \n",
              "1191800  721 miles  \n",
              "1191801  731 miles  \n",
              "1191802  731 miles  \n",
              "1191803  508 miles  \n",
              "1191804  306 miles  \n",
              "\n",
              "[1191805 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ytu1SnzEW5p-"
      },
      "source": [
        "So walking through each column identifies the issues that this dataset might have. Let's tackle the **distance** issue first. It looks like this is meant to be _integer_ encoded (notice that I said that distances could be floats in the table at the beginning of this lecture. Why the change of mind?), and they have 'miles' appended to the end of the number. We can do a lot more stuff with numeric data than text data which represents numbers, so lets first convert this to an int.\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td> </td>\n",
        "        <td><b>OrderID</b></td>\n",
        "        <td><b>Cost</b></td>\n",
        "        <td><b>Quantity</b></td>\n",
        "        <td><b>Address</b></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>0</td>\n",
        "        <td>1234</td>\n",
        "        <td>£1000.00</td>\n",
        "        <td>10</td>\n",
        "        <td>123 Fake Street</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>1</td>\n",
        "        <td>7890</td>\n",
        "        <td>£35.50</td>\n",
        "        <td>3</td>\n",
        "        <td>789 Real Road</td>\n",
        "    </tr>\n",
        "    \n",
        "</table>\n",
        "\n",
        "In the above table, we can see that cost should be a float - however it has a £ symbol attached to it. To use this column as a float, we need to remove the £. Before doing this, however, let's take a look at the datatypes of the columns. This is done by calling the `.dtypes` attribute on our dataframe. In the above example case, we would have returned:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>OrderID</td>\n",
        "        <td>int64</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Cost</td>\n",
        "        <td>object</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Quantity</td>\n",
        "        <td>int64</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Address</td>\n",
        "        <td>object</td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "We can also use `.info()`, which returns us the amount of null information in each column too (we'll cover how to deal with null/missing values soon)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5LlFnPYW5qA",
        "outputId": "f1acfd29-e4c2-4d11-da18-51c95c01bfa1"
      },
      "source": [
        "## Find the object types for each column using .dtypes\n",
        "x = flights_df.dtypes\n",
        "print(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRANSACTIONID          int64\n",
            "FLIGHTDATE             int64\n",
            "AIRLINECODE           object\n",
            "AIRLINENAME           object\n",
            "TAILNUM               object\n",
            "FLIGHTNUM              int64\n",
            "ORIGINAIRPORTCODE     object\n",
            "ORIGAIRPORTNAME       object\n",
            "ORIGINCITYNAME        object\n",
            "ORIGINSTATE           object\n",
            "ORIGINSTATENAME       object\n",
            "DESTAIRPORTCODE       object\n",
            "DESTAIRPORTNAME       object\n",
            "DESTCITYNAME          object\n",
            "DESTSTATE             object\n",
            "DESTSTATENAME         object\n",
            "CRSDEPTIME             int64\n",
            "DEPTIME              float64\n",
            "DEPDELAY             float64\n",
            "TAXIOUT              float64\n",
            "WHEELSOFF            float64\n",
            "WHEELSON             float64\n",
            "TAXIIN               float64\n",
            "CRSARRTIME             int64\n",
            "ARRTIME              float64\n",
            "ARRDELAY             float64\n",
            "CRSELAPSEDTIME       float64\n",
            "ACTUALELAPSEDTIME    float64\n",
            "CANCELLED             object\n",
            "DIVERTED              object\n",
            "DISTANCE              object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbobJLy4W5qA",
        "outputId": "c94fad83-8933-4d0c-d48b-0f2231710a72"
      },
      "source": [
        "## Find the object types and number of nulls using .info() \n",
        "y = flights_df.info()\n",
        "print(y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1191805 entries, 0 to 1191804\n",
            "Data columns (total 31 columns):\n",
            " #   Column             Non-Null Count    Dtype  \n",
            "---  ------             --------------    -----  \n",
            " 0   TRANSACTIONID      1191805 non-null  int64  \n",
            " 1   FLIGHTDATE         1191805 non-null  int64  \n",
            " 2   AIRLINECODE        1191805 non-null  object \n",
            " 3   AIRLINENAME        1191805 non-null  object \n",
            " 4   TAILNUM            1034988 non-null  object \n",
            " 5   FLIGHTNUM          1191805 non-null  int64  \n",
            " 6   ORIGINAIRPORTCODE  1191805 non-null  object \n",
            " 7   ORIGAIRPORTNAME    1191805 non-null  object \n",
            " 8   ORIGINCITYNAME     1191805 non-null  object \n",
            " 9   ORIGINSTATE        1180963 non-null  object \n",
            " 10  ORIGINSTATENAME    1180963 non-null  object \n",
            " 11  DESTAIRPORTCODE    1191805 non-null  object \n",
            " 12  DESTAIRPORTNAME    1191805 non-null  object \n",
            " 13  DESTCITYNAME       1191805 non-null  object \n",
            " 14  DESTSTATE          1180967 non-null  object \n",
            " 15  DESTSTATENAME      1180967 non-null  object \n",
            " 16  CRSDEPTIME         1191805 non-null  int64  \n",
            " 17  DEPTIME            1163470 non-null  float64\n",
            " 18  DEPDELAY           1163470 non-null  float64\n",
            " 19  TAXIOUT            1011833 non-null  float64\n",
            " 20  WHEELSOFF          1011791 non-null  float64\n",
            " 21  WHEELSON           1010225 non-null  float64\n",
            " 22  TAXIIN             1010320 non-null  float64\n",
            " 23  CRSARRTIME         1191805 non-null  int64  \n",
            " 24  ARRTIME            1161439 non-null  float64\n",
            " 25  ARRDELAY           1160545 non-null  float64\n",
            " 26  CRSELAPSEDTIME     1191383 non-null  float64\n",
            " 27  ACTUALELAPSEDTIME  1160545 non-null  float64\n",
            " 28  CANCELLED          1191805 non-null  object \n",
            " 29  DIVERTED           1191805 non-null  object \n",
            " 30  DISTANCE           1191805 non-null  object \n",
            "dtypes: float64(10), int64(5), object(16)\n",
            "memory usage: 281.9+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haWLEhU_W5qB"
      },
      "source": [
        "If we were to sum our above <b>cost</b> column (`sales['cost'].sum()`), something akin to the following would be returned:\n",
        "```£1000.00£35.50£46.10£76.35```...\n",
        "\n",
        "Obviously this isn't what we want.. we'd rather have all our costs summed.\n",
        "\n",
        "Try the same with the 'DISTANCE' column with our flights data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oij54e_9W5qD",
        "outputId": "eb5fee93-defa-4e9e-917b-1fd156ffafdb"
      },
      "source": [
        "## Sum the first 10 instances of 'DISTANCE' column in the flights data.\n",
        "# Be aware about where you slice ;). What's the technical difference between slicing before the .sum() and after? \n",
        "z = flights_df.iloc[:11,30:31]\n",
        "#z = flights_df.sum(axis=(0,9) columns(30))\n",
        "print(z)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      DISTANCE\n",
            "0    580 miles\n",
            "1    744 miles\n",
            "2    718 miles\n",
            "3    487 miles\n",
            "4    744 miles\n",
            "5    289 miles\n",
            "6    569 miles\n",
            "7   1240 miles\n",
            "8    223 miles\n",
            "9    677 miles\n",
            "10   328 miles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIyN6Vk5W5qD"
      },
      "source": [
        "So to resolve the issue with our sales data, we need to do two things:\n",
        "1. Remove the '£'\n",
        "2. Convert the column to a float data type\n",
        "\n",
        "This would be done as follows:\n",
        "```python\n",
        "sales['cost'] = sales['cost'].str.strip('£')\n",
        "sales['cost'] = sales['cost'].astype('float64')\n",
        "```\n",
        "\n",
        "Armed with this knowledge, let's convert the distance column to an int!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPZYihD8W5qE",
        "outputId": "7061c95d-2f01-4834-bb7c-02d956bd27b1"
      },
      "source": [
        "## Remove the ' miles' from the dataframe\n",
        "flights_df['DISTANCE'] = flights_df['DISTANCE'].str.strip('miles')\n",
        "\n",
        "## Convert the column to an int64 type\n",
        "flights_df['DISTANCE'] = flights_df['DISTANCE'].astype('float64')\n",
        "\n",
        "## Verify that the column has converted to an int sucessfully\n",
        "flights_df.dtypes"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TRANSACTIONID          int64\n",
              "FLIGHTDATE             int64\n",
              "AIRLINECODE           object\n",
              "AIRLINENAME           object\n",
              "TAILNUM               object\n",
              "FLIGHTNUM              int64\n",
              "ORIGINAIRPORTCODE     object\n",
              "ORIGAIRPORTNAME       object\n",
              "ORIGINCITYNAME        object\n",
              "ORIGINSTATE           object\n",
              "ORIGINSTATENAME       object\n",
              "DESTAIRPORTCODE       object\n",
              "DESTAIRPORTNAME       object\n",
              "DESTCITYNAME          object\n",
              "DESTSTATE             object\n",
              "DESTSTATENAME         object\n",
              "CRSDEPTIME             int64\n",
              "DEPTIME              float64\n",
              "DEPDELAY             float64\n",
              "TAXIOUT              float64\n",
              "WHEELSOFF            float64\n",
              "WHEELSON             float64\n",
              "TAXIIN               float64\n",
              "CRSARRTIME             int64\n",
              "ARRTIME              float64\n",
              "ARRDELAY             float64\n",
              "CRSELAPSEDTIME       float64\n",
              "ACTUALELAPSEDTIME    float64\n",
              "CANCELLED             object\n",
              "DIVERTED              object\n",
              "DISTANCE             float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfBR5VTFW5qF"
      },
      "source": [
        "Cool! Ok, so that's how we can convert messy text data to numbers. Let's look at converting data to categorical values now.\n",
        "\n",
        "In our dataset, we have many columns which could be categorical. Can you identify which ones they are?\n",
        "<br>\n",
        "<details>\n",
        "    <summary><b>></b> Categorical variables (click to reveal)</summary>\n",
        "    <ul>\n",
        "        <li>AIRLINECODE</li>\n",
        "        <li>AIRLINENAME</li>\n",
        "        <li>ORIGINAIRPORTCODE</li>\n",
        "        <li>ORIGAIRPORTNAME</li>\n",
        "        <li>ORIGINCITYNAME</li>\n",
        "        <li>ORIGINSTATE</li>\n",
        "        <li>ORIGINSTATENAME</li>\n",
        "        <li>DESTAIRPORTCODE</li>\n",
        "        <li>DESTAIRPORTNAME</li>\n",
        "        <li>DESTCITYNAME</li>\n",
        "        <li>DESTSTATE</li>\n",
        "        <li>DESTSTATENAME</li>\n",
        "    </ul>\n",
        "</details>\n",
        "\n",
        "Using the `.describe()` method, we can identify more information about a particular column. Let's use `AIRLINECODE` as an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVe-TKJXW5qG",
        "outputId": "fff0f760-b852-4eef-ad50-0d6ad3df3128"
      },
      "source": [
        "flights_df['AIRLINECODE'].describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     1191805\n",
              "unique         26\n",
              "top            WN\n",
              "freq       189985\n",
              "Name: AIRLINECODE, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp1Qh2NOW5qH",
        "outputId": "d311c415-02e5-49e5-fb37-9cbe8d3c476d"
      },
      "source": [
        "flights_df['AIRLINECODE']"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          WN\n",
              "1          CO\n",
              "2          WN\n",
              "3          WN\n",
              "4          CO\n",
              "           ..\n",
              "1191800    EV\n",
              "1191801    DL\n",
              "1191802    DL\n",
              "1191803    EV\n",
              "1191804    EV\n",
              "Name: AIRLINECODE, Length: 1191805, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJqlWzEUW5qH"
      },
      "source": [
        "We get some (midly) useful statistics returned when we run `.describe()` over this variable. However, we can see that the datatype of this column has been interpreted as `object`. From the data types table we introduced earlier, we can see that support for categories exist. Let's convert this to a category and see the difference from the describe method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5EONt6gW5qI",
        "outputId": "c3f5c73b-8156-47b8-8987-864b9fde4824"
      },
      "source": [
        "flights_df['AIRLINECODE'] = flights_df['AIRLINECODE'].astype('category')\n",
        "flights_df['AIRLINECODE']"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          WN\n",
              "1          CO\n",
              "2          WN\n",
              "3          WN\n",
              "4          CO\n",
              "           ..\n",
              "1191800    EV\n",
              "1191801    DL\n",
              "1191802    DL\n",
              "1191803    EV\n",
              "1191804    EV\n",
              "Name: AIRLINECODE, Length: 1191805, dtype: category\n",
              "Categories (26, object): ['9E', 'AA', 'AS', 'B6', ..., 'VX', 'WN', 'XE', 'YV']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuhMqoHpW5qI",
        "outputId": "b5396188-7f6f-4540-a969-aadbcf2a5ae7"
      },
      "source": [
        "flights_df['AIRLINECODE'].describe()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     1191805\n",
              "unique         26\n",
              "top            WN\n",
              "freq       189985\n",
              "Name: AIRLINECODE, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcTt3fBZW5qJ"
      },
      "source": [
        "No visible difference `.describe()` method really (weirdly it still returns dtype of object 🤔)! Although we do see a new attribute when displying the actual information about the column. Either way, lets take a quick detour under the hood and see the advantages of representihng things as categories. We'll make use of the `.info()` method to look at our memory consumption "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBrXti17W5qK",
        "outputId": "20355db4-d205-416e-e490-c90cdd7b8327"
      },
      "source": [
        "flights_df['AIRLINECODE'] = flights_df['AIRLINECODE'].astype('object')\n",
        "flights_df.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1191805 entries, 0 to 1191804\n",
            "Data columns (total 31 columns):\n",
            " #   Column             Non-Null Count    Dtype  \n",
            "---  ------             --------------    -----  \n",
            " 0   TRANSACTIONID      1191805 non-null  int64  \n",
            " 1   FLIGHTDATE         1191805 non-null  int64  \n",
            " 2   AIRLINECODE        1191805 non-null  object \n",
            " 3   AIRLINENAME        1191805 non-null  object \n",
            " 4   TAILNUM            1034988 non-null  object \n",
            " 5   FLIGHTNUM          1191805 non-null  int64  \n",
            " 6   ORIGINAIRPORTCODE  1191805 non-null  object \n",
            " 7   ORIGAIRPORTNAME    1191805 non-null  object \n",
            " 8   ORIGINCITYNAME     1191805 non-null  object \n",
            " 9   ORIGINSTATE        1180963 non-null  object \n",
            " 10  ORIGINSTATENAME    1180963 non-null  object \n",
            " 11  DESTAIRPORTCODE    1191805 non-null  object \n",
            " 12  DESTAIRPORTNAME    1191805 non-null  object \n",
            " 13  DESTCITYNAME       1191805 non-null  object \n",
            " 14  DESTSTATE          1180967 non-null  object \n",
            " 15  DESTSTATENAME      1180967 non-null  object \n",
            " 16  CRSDEPTIME         1191805 non-null  int64  \n",
            " 17  DEPTIME            1163470 non-null  float64\n",
            " 18  DEPDELAY           1163470 non-null  float64\n",
            " 19  TAXIOUT            1011833 non-null  float64\n",
            " 20  WHEELSOFF          1011791 non-null  float64\n",
            " 21  WHEELSON           1010225 non-null  float64\n",
            " 22  TAXIIN             1010320 non-null  float64\n",
            " 23  CRSARRTIME         1191805 non-null  int64  \n",
            " 24  ARRTIME            1161439 non-null  float64\n",
            " 25  ARRDELAY           1160545 non-null  float64\n",
            " 26  CRSELAPSEDTIME     1191383 non-null  float64\n",
            " 27  ACTUALELAPSEDTIME  1160545 non-null  float64\n",
            " 28  CANCELLED          1191805 non-null  object \n",
            " 29  DIVERTED           1191805 non-null  object \n",
            " 30  DISTANCE           1191805 non-null  float64\n",
            "dtypes: float64(11), int64(5), object(15)\n",
            "memory usage: 281.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynzWCvPxW5qK",
        "outputId": "29ad4950-8d84-4601-c355-794b85d76293"
      },
      "source": [
        "flights_df['AIRLINECODE'] = flights_df['AIRLINECODE'].astype('category')\n",
        "flights_df.info()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1191805 entries, 0 to 1191804\n",
            "Data columns (total 31 columns):\n",
            " #   Column             Non-Null Count    Dtype   \n",
            "---  ------             --------------    -----   \n",
            " 0   TRANSACTIONID      1191805 non-null  int64   \n",
            " 1   FLIGHTDATE         1191805 non-null  int64   \n",
            " 2   AIRLINECODE        1191805 non-null  category\n",
            " 3   AIRLINENAME        1191805 non-null  object  \n",
            " 4   TAILNUM            1034988 non-null  object  \n",
            " 5   FLIGHTNUM          1191805 non-null  int64   \n",
            " 6   ORIGINAIRPORTCODE  1191805 non-null  object  \n",
            " 7   ORIGAIRPORTNAME    1191805 non-null  object  \n",
            " 8   ORIGINCITYNAME     1191805 non-null  object  \n",
            " 9   ORIGINSTATE        1180963 non-null  object  \n",
            " 10  ORIGINSTATENAME    1180963 non-null  object  \n",
            " 11  DESTAIRPORTCODE    1191805 non-null  object  \n",
            " 12  DESTAIRPORTNAME    1191805 non-null  object  \n",
            " 13  DESTCITYNAME       1191805 non-null  object  \n",
            " 14  DESTSTATE          1180967 non-null  object  \n",
            " 15  DESTSTATENAME      1180967 non-null  object  \n",
            " 16  CRSDEPTIME         1191805 non-null  int64   \n",
            " 17  DEPTIME            1163470 non-null  float64 \n",
            " 18  DEPDELAY           1163470 non-null  float64 \n",
            " 19  TAXIOUT            1011833 non-null  float64 \n",
            " 20  WHEELSOFF          1011791 non-null  float64 \n",
            " 21  WHEELSON           1010225 non-null  float64 \n",
            " 22  TAXIIN             1010320 non-null  float64 \n",
            " 23  CRSARRTIME         1191805 non-null  int64   \n",
            " 24  ARRTIME            1161439 non-null  float64 \n",
            " 25  ARRDELAY           1160545 non-null  float64 \n",
            " 26  CRSELAPSEDTIME     1191383 non-null  float64 \n",
            " 27  ACTUALELAPSEDTIME  1160545 non-null  float64 \n",
            " 28  CANCELLED          1191805 non-null  object  \n",
            " 29  DIVERTED           1191805 non-null  object  \n",
            " 30  DISTANCE           1191805 non-null  float64 \n",
            "dtypes: category(1), float64(11), int64(5), object(14)\n",
            "memory usage: 273.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Us0nvF0W5qL"
      },
      "source": [
        "We see our our memory usage has dropped by around 8mb by just converting this one column to a category! Ok, yes admittedly this isn't that big of a deal when working with data for this size, but remember, this saving on memory comes from just one of the many categorical columns we have.\n",
        "\n",
        "So why is this? Well, under the hood, Pandas represents categories as integer types. In fact, something that you may come across when working with other datasets is explictly seeing a category column encoded as integers. Let's modify our dataframe to see what happens when this could be the case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "Q4B1LE00W5qL",
        "outputId": "f2805947-dafe-49c4-c7a0-4cd041ad05e4"
      },
      "source": [
        "flights_df['AIRLINECODE_ASINT'] = flights_df['AIRLINECODE'].cat.codes.astype('int64')\n",
        "flights_df['AIRLINECODE_ASINT']"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2710db04ca2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflights_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AIRLINECODE_ASINT'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflights_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AIRLINECODE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mflights_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AIRLINECODE_ASINT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5135\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5136\u001b[0m         ):\n\u001b[0;32m-> 5137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5139\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2562\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   2568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2570\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .cat accessor with a 'category' dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_delegate_property_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can only use .cat accessor with a 'category' dtype"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1F1ws5lW5qM"
      },
      "source": [
        "When we run `.describe()` we can see statistics returned which don't exactly make sense for our column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "I-MGaEXyW5qM",
        "outputId": "9beaa803-23b7-45cb-ca9e-2163a8319811"
      },
      "source": [
        "flights_df['AIRLINECODE_ASINT'].describe()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'AIRLINECODE_ASINT'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-99827303a220>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflights_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AIRLINECODE_ASINT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'AIRLINECODE_ASINT'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCZFWj9rW5qM"
      },
      "source": [
        "It doesn't make sense for a categorical column to have a mean or any other those statistical propteries. We'll look at why this in a bit more detail further down the line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "Uaw2Z2ddW5qM",
        "outputId": "3c9b6eac-a00e-46ac-c1f8-da59a4ac3d46"
      },
      "source": [
        "flights_df = flights_df.drop('AIRLINECODE_ASINT', 1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-a962bf7a81c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflights_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflights_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AIRLINECODE_ASINT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4172\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4174\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m         )\n\u001b[1;32m   4176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3889\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3922\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3923\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['AIRLINECODE_ASINT'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twVjGoKeW5qN"
      },
      "source": [
        "What datatypes (Numeric, datetime, text, or categorical) would you group the following examples as?:\n",
        "\n",
        "- Description of an item\n",
        "- Yearly income\n",
        "- Size of clothing\n",
        "- Arrival time of a plane\n",
        "- Birthdays of this cohort\n",
        "- Flavours of milkshakes at McDonalds\n",
        "- First half of a postcode\n",
        "- Full postcode\n",
        "- The time it took for runners to complete a 5K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xYYU3xQW5qN"
      },
      "source": [
        "## Duplicate Values\n",
        "\n",
        "Another common issue that we might face is **duplicate values**. As the name suggests, this occurs when we have the same values repeated across multiple rows or columns:\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><b>first_name</b></td>\n",
        "        <td><b>last_name</b></td>\n",
        "        <td><b>address</b></td>\n",
        "        <td><b>age</b></td>\n",
        "        <td><b>income</b></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>John</td>\n",
        "        <td>Doe</td>\n",
        "        <td>123 Real Street</td>\n",
        "        <td>25</td>\n",
        "        <td>£28000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Jane</td>\n",
        "        <td>Smith</td>\n",
        "        <td>789 Fake Road</td>\n",
        "        <td>29</td>\n",
        "        <td>£32000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Jane</td>\n",
        "        <td>Smith</td>\n",
        "        <td>789 Fake Road</td>\n",
        "        <td>29</td>\n",
        "        <td>£32000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Mark</td>\n",
        "        <td>Smith</td>\n",
        "        <td>789 Fake Road</td>\n",
        "        <td>31</td>\n",
        "        <td>£32000</td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "In the above example, we can see that Jane Smith has two entries directly duplicated. However, in some cases, we might see extremely similar entries:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><b>first_name</b></td>\n",
        "        <td><b>last_name</b></td>\n",
        "        <td><b>address</b></td>\n",
        "        <td><b>age</b></td>\n",
        "        <td><b>income</b></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>John</td>\n",
        "        <td>Doe</td>\n",
        "        <td>123 Real Street</td>\n",
        "        <td>25</td>\n",
        "        <td>£28000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Jane</td>\n",
        "        <td>Smith</td>\n",
        "        <td>789 Fake Road</td>\n",
        "        <td><b>28</b></td>\n",
        "        <td>£32000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Jane</td>\n",
        "        <td>Smith</td>\n",
        "        <td>789 Fake Road</td>\n",
        "        <td>29</td>\n",
        "        <td>£32000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Mark</td>\n",
        "        <td>Smith</td>\n",
        "        <td>789 Fake Road</td>\n",
        "        <td>31</td>\n",
        "        <td>£32000</td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "(The age difference between both Jane Smith's). This type of duplicate error is most likely due to a data entry issue or a resubmission of whatever form Jane had submitted - which was entered into the database without removing her old entry. \n",
        "\n",
        "More often than not though, duplicate data arises from either bugs/design patterns in data pipelines, or most commonly, due to database joins and data consolidation from various datasets/databases, which may retain the duplicate values.\n",
        "\n",
        "Pandas provides us with a [`.duplicated()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html) method. Let's use this over our dataframe to see what it returns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geg4257JW5qO",
        "outputId": "8c3bc3cc-1d18-4f3a-9af4-e7ff7efaf49a"
      },
      "source": [
        "flights_df.duplicated()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          False\n",
              "1          False\n",
              "2          False\n",
              "3          False\n",
              "4          False\n",
              "           ...  \n",
              "1191800    False\n",
              "1191801    False\n",
              "1191802    False\n",
              "1191803    False\n",
              "1191804    False\n",
              "Length: 1191805, dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzK5SUZ0W5qP"
      },
      "source": [
        "Note that we can `.sum()` over boolean values. Basically, False's are interpreted as 0s and True's as 1. So by summing over the dataframe, we can get the total number of duplicate values! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cZ4WX8sW5qP",
        "outputId": "1ffcefd5-5bf2-41de-84aa-463bf63a31d8"
      },
      "source": [
        "flights_df.duplicated().sum()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IljX93C-W5qP"
      },
      "source": [
        "No duplicate values!! This is good right? Well... not necessarily. Remind yourself of the second Jane Smith example above. The duplicated method would not have returned true because the whole row wasn't an exact duplicate. To tackle this issue, the `.duplicated()` method takes in two arguments: `subset` and `keep`. For the subset argument, provide a list of column names we want to check duplicates over, and the keep argument takes on 1 of 3 values: `first`, `last`, or `False`. From the documentation:\n",
        "- `first` : Mark duplicates as True except for the first occurrence.\n",
        "- `last` : Mark duplicates as True except for the last occurrence.\n",
        "- `False` : Mark all duplicates as True.\n",
        "\n",
        "In many cases, picking the subset is more of an art form than a science. Your intuition is going to be king."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btfYpcNMW5qP"
      },
      "source": [
        "## Find the duplicates on the flights dataframe over the following columns with keep = False:\n",
        " # \"ORIGAIRPORTNAME\", \"DESTAIRPORTNAME\", \"AIRLINECODE\", \"FLIGHTDATE\", \"CRSDEPTIME\", \"DEPTIME\", \"ARRTIME\"\n",
        " # Assign this to the variable 'duplicates'\n",
        " # Why did I choose these column names? Would you have chosen others?\n",
        "\n",
        "    \n",
        "# Using df[duplicates], we are returned the data points where duplicates exist.\n",
        "## Return the duplicates for the flights dataframe\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gulRkch_W5qQ"
      },
      "source": [
        "As a secondary observation, we see that `TAILNUM` also takes on a value of `UNKNOW` for missing values. We'll make a note of this so we can deal with it later.\n",
        "\n",
        "We can use the [`.sort_values()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html) method to sort our dataframe. Read the documentation and use this method to sort the dataframe on a column name that you think is appropiate (one that allows you to easily verify whether the entries returned are valid duplicates). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT08IGajW5qQ"
      },
      "source": [
        "## Sort the duplicated values by an appropiate index #by age?\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QElMsHNsW5qR",
        "outputId": "843ed955-9fb0-4bab-d5a2-98e96aedd37c"
      },
      "source": [
        "flights_df[\"CRSARRTIME\"].isna().sum()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEuITurAW5qR"
      },
      "source": [
        "## Dealing with duplicate values\n",
        "\n",
        "So.. how do we deal with duplicate values? Well, we only need one entry - not both - so we have one of two options:\n",
        "1. Average over duplicate values where possible\n",
        "2. Drop one of the duplicated rows (or many in the case of one entry having multiple duplicates)\n",
        "\n",
        "\n",
        "### Averaging\n",
        "\n",
        "Averaging over duplicate values can only really be performed on datatypes which make sense. In the above table, the first two entries have valid times that we can average over. In general, the way we average is by grouping on relevant columns (via `.groupby()`), and chaining this with the `.agg()` function. In this case, we want to group on our subset of columns apart from the columns of interest (i.e. to times). Our argument to `.agg()` is a dictionary with key value pairs of column names and the aggregation function we want to apply over them (e.g. sum, difference, mean etc).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "JXItN7q_W5qR",
        "outputId": "c1b96faf-aa7a-4bed-d236-d884e5b3fdac"
      },
      "source": [
        "summaries = {\"CRSARRTIME\": \"mean\", \"ARRTIME\": \"mean\", \"ARRDELAY\": \"mean\", \"CRSELAPSEDTIME\": \"mean\", \"ACTUALELAPSEDTIME\": \"mean\"}\n",
        "\n",
        "grouped_duplicates = flights_df[duplicates].groupby([\"FLIGHTDATE\", \"AIRLINECODE\", \"ORIGAIRPORTNAME\", \"DESTAIRPORTNAME\"])\n",
        "grouped_duplicates_min_transactionid = grouped_duplicates[\"TRANSACTIONID\"].min().reset_index()\n",
        "\n",
        "f_df_duplicates = pd.merge(\n",
        "    grouped_duplicates_min_transactionid,\n",
        "    grouped_duplicates.agg(summaries).reset_index(),\n",
        "    how=\"inner\"\n",
        ").sort_values(\"TRANSACTIONID\")\n",
        "\n",
        "f_df_duplicates\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-c255d3e3581f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msummaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"CRSARRTIME\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ARRTIME\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ARRDELAY\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CRSELAPSEDTIME\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ACTUALELAPSEDTIME\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrouped_duplicates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflights_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mduplicates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FLIGHTDATE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AIRLINECODE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ORIGAIRPORTNAME\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DESTAIRPORTNAME\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgrouped_duplicates_min_transactionid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped_duplicates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TRANSACTIONID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'duplicates' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuAGHhMdW5qS"
      },
      "source": [
        "# Why are there so many new NaN's in the TRANSACTIONID field now?\n",
        "## How should we get rid of them?\n",
        "\n",
        "\n",
        "## Re-encode TRANSACTIONID to int64\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "GSaqun0JW5qS"
      },
      "source": [
        "# The .update() method allows us to update records in one dataframe from values in an other\n",
        "# Some way of 'linking' which records to overwrite/update is needed if we do not want to use the default dataframe index\n",
        "## So, using the .set_index() method, set our flights_df and f_df_duplicates new index to a unique indentifer key they both share\n",
        "\n",
        "\n",
        "# Now we can update the flights_df dataframe with the new dataframe\n",
        "\n",
        "\n",
        "## And finally, we may optionally reset the index to obtain the default dataframe indexing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnWSUhhPW5qS"
      },
      "source": [
        "flights_df[flights_df[\"TRANSACTIONID\"]==1974100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFxl9psuW5qT"
      },
      "source": [
        "##### Dropping duplicates\n",
        "\n",
        "Regarding dropping duplicates, Pandas provides us with a `.drop_duplicates()` method which takes three arguments:\n",
        "1. `subset`\n",
        "2. `keep`\n",
        "3. `inplace` - a boolean value of whether we want to perform the operation inplace or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPzEao2KW5qU"
      },
      "source": [
        "subset = [\"ORIGAIRPORTNAME\", \"DESTAIRPORTNAME\", \"AIRLINECODE\", \"FLIGHTDATE\", \"CRSDEPTIME\", \"DEPTIME\", \"ARRTIME\"]\n",
        "## Using inplace = True, drop the duplicates. Think about what value we should provide to the keep argument\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "UFzAMWNoW5qZ"
      },
      "source": [
        "flights_df[duplicates]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFdoZ9xaW5qa"
      },
      "source": [
        "## Categorical data\n",
        "\n",
        "We touched on categorical data earlier on in this notebook (with categories), but here we take a more ridigly define the concept. Categorical data variables take on their value from a predefined set of categories. We saw the example above with AIRLINE codes.\n",
        "\n",
        "Would you say the following variables categorical or not?\n",
        "- TAILNUM\n",
        "- FLIGHTNUM\n",
        "- ORIGINAIRPORTCODE\n",
        "- ORIGAIRPORTNAME\n",
        "- CANCELLED\n",
        "\n",
        "What about the columns in the following table?\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><b>First Name</b></td>\n",
        "        <td><b>Last Name</b></td>\n",
        "        <td><b>Age</b></td>\n",
        "        <td><b>Address</b></td>\n",
        "        <td><b>District Postcode</b></td>\n",
        "        <td><b>Full Postcode</b></td>\n",
        "        <td><b>Married</b><td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>John</td>\n",
        "        <td>Doe</td>\n",
        "        <td>31</td>\n",
        "        <td>123 Fake Street, Realtown</td>\n",
        "        <td>RT1</td>\n",
        "        <td>RT1 3NV</td>\n",
        "        <td>True</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Diane</td>\n",
        "        <td>Smith</td>\n",
        "        <td>31</td>\n",
        "        <td>42 World Road, Realtown</td>\n",
        "        <td>RT2</td>\n",
        "        <td>RT2 7XU</td>\n",
        "        <td>False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Kate</td>\n",
        "        <td>Doe</td>\n",
        "        <td>29</td>\n",
        "        <td>123 Fake Street, Realtown</td>\n",
        "        <td>RT1</td>\n",
        "        <td>RT1 3NV</td>\n",
        "        <td>False</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Charlie</td>\n",
        "        <td>Doe</td>\n",
        "        <td>33</td>\n",
        "        <td>789 Real Road, Fakecity</td>\n",
        "        <td>FC2</td>\n",
        "        <td>FC2 9ER</td>\n",
        "        <td>True</td>        \n",
        "    </tr>    \n",
        "</table>\n",
        "\n",
        "Categorical data can only take on one of a finite set of values and it is impossible for them to go beyond these predefined categories. However, during the data collection process, noise in our data could occur (e.g. if our cateogorical data was collected via a free entry text box).\n",
        "\n",
        "There are a couple of ways to deal with inconsistent categories:\n",
        "1. Dropping data\n",
        "2. Remapping the categories\n",
        "3. Inferring the categories\n",
        "\n",
        "### Dropping Data\n",
        "\n",
        "The first approach we'll look at membership constraints over is the `ORIGINSTATENAME` variable. Dropping data is required when we have a value which in our entry isn't (conceptually) in the predinfed set of categories. We'll start by returning all the unique values in the variable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnY4Ee31W5qa"
      },
      "source": [
        "## Construct a set of the unique values in ORIGINSTATENAME #.unique()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW06QGuZW5qb"
      },
      "source": [
        "Now let's say we received some new entries which had statenames not present in that predefined set of categories (for example, \"Fakestate\"). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYuqzQRYW5qb"
      },
      "source": [
        "## using the .at() or .iat() methods on flights_df, modify one of the rows \n",
        "## in our table to have its ORIGINSTATENAME as Fakestate\n",
        "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.at.html\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr7DQdnuW5qb"
      },
      "source": [
        "# Displays the unique entries in ORIGINSTATENAME in our modified dataframe\n",
        "flights_df[\"ORIGINSTATENAME\"].unique()\n",
        "# OR set(flights_df[\"ORIGINSTATENAME\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehc_qdJCW5qb"
      },
      "source": [
        "## Using set operations, find the difference between the origin states in our dataframe and our predefined list  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Waeq7Sz6W5qc"
      },
      "source": [
        "# This .isin method returns all rows from the dataframe where the Series meets the condition its passed\n",
        "inconsistent_rows = flights_df[\"ORIGINSTATENAME\"].isin(inconsistent_categories)\n",
        "flights_df[inconsistent_rows]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzAFHFvpW5qc"
      },
      "source": [
        "# Nifty trick we can use to drop rows\n",
        "# What do you think ~ means?\n",
        "flights_df = flights_df[~inconsistent_rows]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch-F_3HzW5qc"
      },
      "source": [
        "### Remapping Categories\n",
        "\n",
        "What we saw above was data that was not present in the predefined set of categories. However, we may also come across some other type of category data issues which are better solved by remapping categories than dropping data. Appropiate places to perform this remapping would be when:\n",
        "1. **Inconsistency in values**: `married`, `not married`, `unmarried`, ` Maried` <br>\n",
        " 1. Be careful of trailing white space too!\n",
        "2. **Converting data to categories or too many categories**: Let's say we had a household income column in our dataframe. \n",
        " 1. We could change this type of data to be categorical by grouping the income (e.g. `0 - 20k`, `20k - 40k`, `40k - 60k`, `60k +` etc).\n",
        " 2. We could also reduce this further to `low_class`, `middle_class`, `upper_class`\n",
        " \n",
        "Let's tackle these in order. In our flights dataframe, the columns `CANCELLED` and `DIVERTED` both take on inconsistent values. Perhaps the safest option is to run `.value_counts()` on one of these columns (`.value_counts()` on runs on type `Series`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5SazKAWW5qc",
        "outputId": "aadc4bce-e4cf-4057-dd4c-5bb05c18e83d"
      },
      "source": [
        "flights_df[\"CANCELLED\"].value_counts()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    637289\n",
              "0        347545\n",
              "F        178357\n",
              "True      16370\n",
              "1          8160\n",
              "T          4084\n",
              "Name: CANCELLED, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FciVF2P8W5qd"
      },
      "source": [
        "Great! So we see that our Falsy values can take on one of three values, and the Truthy values are similar too. We can arbitrarily whichever ones of these we want to use moving forward. For explicitness, let's choose False and True respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6kslTnuW5qd"
      },
      "source": [
        "## Use the replace method: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.replace.html\n",
        "## To replace 0, F, 1 and T to their relevant values for the CANCELLED column\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTMSUDByW5qd",
        "outputId": "2a453512-497a-40b0-d193-e71a9317a69a"
      },
      "source": [
        "flights_df[\"DIVERTED\"].value_counts()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "F        426572\n",
              "False    407681\n",
              "0        354906\n",
              "T           966\n",
              "True        881\n",
              "1           799\n",
              "Name: DIVERTED, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv5gXyzYW5qm",
        "outputId": "9e7eacf3-fcc6-4e66-9bb1-6879d231a351"
      },
      "source": [
        "# We can alternatively use a dictionary to \"reduce\" our categories.\n",
        "mapping = {\"F\": \"False\", \"0\": \"False\", \"1\": \"True\", \"T\": \"True\"}\n",
        "flights_df[\"DIVERTED\"] = flights_df[\"DIVERTED\"].replace(mapping)\n",
        "flights_df[\"DIVERTED\"].value_counts()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    1189159\n",
              "True        2646\n",
              "Name: DIVERTED, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P-Y7UedW5qn"
      },
      "source": [
        "As previously mentioned, another situation in which we may want to remap categories is when we want to reduce the number of values in a column. In our case, let's say a flight company would like to categorise the flights based on how far they've travel. So, anything between 0 and 1000 miles is `short`, between 1000 and 2500 is `medium` and 2500+ is `long`.\n",
        "\n",
        "Here, we can use the [`.cut`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html) method to segment our data. We will provide three argments to the function:\n",
        "1. The `Series` we want to segment\n",
        "2. The bins - that is, a list of ranges we'll be wanting to segment against\n",
        "3. The labels - that is, a list of labels we want to assign to each of our bins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "tYcmYceTW5qy",
        "outputId": "90bc3419-6584-4248-9c02-ddd3145f2784"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "bins = [0, 1000, 2500, np.inf]\n",
        "labels = [\"short\", \"medium\", \"long\"]\n",
        "flights_df[\"DISTANCE_CATEGORY\"] = pd.cut(flights_df[\"DISTANCE\"], bins=bins, labels=labels)\n",
        "\n",
        "flights_df[[\"DISTANCE\", \"DISTANCE_CATEGORY\"]]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-fc722d81c3bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"short\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"medium\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"long\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mflights_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DISTANCE_CATEGORY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflights_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DISTANCE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mflights_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DISTANCE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DISTANCE_CATEGORY\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36mcut\u001b[0;34m(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mduplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mduplicates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mordered\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36m_bins_to_cuts\u001b[0;34m(x, bins, right, labels, precision, include_lowest, dtype, duplicates, ordered)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0mside\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"left\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mright\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"right\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_int64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mside\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minclude_lowest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "YDrHV6IpW5qz",
        "outputId": "ecb2a088-731d-4f1e-8b4b-1bddd4107686"
      },
      "source": [
        "flights_df[flights_df[\"DISTANCE_CATEGORY\"] == \"long\"]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'DISTANCE_CATEGORY'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-402dafba5ee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflights_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflights_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DISTANCE_CATEGORY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"long\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'DISTANCE_CATEGORY'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHx322V7W5q0"
      },
      "source": [
        "### Dealing with Datetimes\n",
        "\n",
        "One common issue you're going to come across is dealing with dates and datetimes (simply a date and a time). Why? Because there are many ways that we can format a date, such as `DD/MM/YYYY`, `MM/DD/YY`, `Xth MONTH YEAR` etc. In our dataframe above, our dates are actually formatted as just one number. Pandas provides us with a useful helper for constructing datetimes - that is, with the [`.to_datetime()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) method.\n",
        "\n",
        "Before we look into this, it's valuable to quickly introduce how dates are typically stored in computers. Typically, dates are calculated against the number of seconds elapsed since **1st January 1970**. When we want to, let's say, find the difference in time between 3/2/2013 16:00 and 21/1/2013 09:00, the program performs its operations on the **Epoch/Unix/POSIX time** for those values, and we can subsequently code something up to provide us the value back back in a format we want (e.g. 13 days, 7 hours). Speaking with numbers:\n",
        "- **3/2/2013 16:00** = 1,359,907,200\n",
        "- **21/1/2013 09:00** = 1,358,758,800\n",
        "\n",
        "Difference in dates = 1,359,907,200 - 1,358,758,800 = 1,148,400 seconds\n",
        "\n",
        "`format(1148400) = 13 days, 7 hours`\n",
        "\n",
        "Great! Ok, so to solidify how you common looking datetimes are formatted:\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><b>Date</b></td>\n",
        "        <td><b>Datetime format</b></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>15th June 2020</td>\n",
        "        <td>%c</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>15/06/2020</td>\n",
        "        <td>%d/%m/%Y</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>06-15-2020</td>\n",
        "        <td>%m-%d-%Y</td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "Let's use the method!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB5yVwoSW5q1"
      },
      "source": [
        "flights_df = pd.read_csv('flights.txt', sep='|')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL7qOpXJ6J1t",
        "outputId": "4b7cc127-1393-4d11-ff6e-2af0e2780cae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(flights_df.head())"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   TRANSACTIONID  FLIGHTDATE AIRLINECODE                     AIRLINENAME  \\\n",
            "0       54548800    20020101          WN      Southwest Airlines Co.: WN   \n",
            "1       55872300    20020101          CO  Continental Air Lines Inc.: CO   \n",
            "2       54388800    20020101          WN      Southwest Airlines Co.: WN   \n",
            "3       54486500    20020101          WN      Southwest Airlines Co.: WN   \n",
            "4       55878700    20020103          CO  Continental Air Lines Inc.: CO   \n",
            "\n",
            "  TAILNUM  FLIGHTNUM ORIGINAIRPORTCODE  \\\n",
            "0  N103@@       1425               ABQ   \n",
            "1  N83872        150               ABQ   \n",
            "2  N334@@        249               ABQ   \n",
            "3  N699@@        902               ABQ   \n",
            "4  N58606        234               ABQ   \n",
            "\n",
            "                                    ORIGAIRPORTNAME ORIGINCITYNAME  \\\n",
            "0  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
            "1  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
            "2  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
            "3  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
            "4  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
            "\n",
            "  ORIGINSTATE ORIGINSTATENAME DESTAIRPORTCODE  \\\n",
            "0          NM      New Mexico             DAL   \n",
            "1          NM      New Mexico             IAH   \n",
            "2          NM      New Mexico             MCI   \n",
            "3          NM      New Mexico             LAS   \n",
            "4          NM      New Mexico             IAH   \n",
            "\n",
            "                                   DESTAIRPORTNAME DESTCITYNAME DESTSTATE  \\\n",
            "0                      DallasTX: Dallas Love Field       Dallas        TX   \n",
            "1  HoustonTX: George Bush Intercontinental/Houston      Houston        TX   \n",
            "2         Kansas CityMO: Kansas City International  Kansas City        MO   \n",
            "3              Las VegasNV: McCarran International    Las Vegas        NV   \n",
            "4  HoustonTX: George Bush Intercontinental/Houston      Houston        TX   \n",
            "\n",
            "  DESTSTATENAME  CRSDEPTIME  DEPTIME  DEPDELAY  TAXIOUT  WHEELSOFF  WHEELSON  \\\n",
            "0         Texas        1425   1425.0       0.0      8.0     1433.0    1648.0   \n",
            "1         Texas        1130   1136.0       6.0     12.0     1148.0    1419.0   \n",
            "2      Missouri        1215   1338.0      83.0      7.0     1345.0    1618.0   \n",
            "3        Nevada        1925   1925.0       0.0      5.0     1930.0    1947.0   \n",
            "4         Texas        1455   1453.0      -2.0     11.0     1504.0    1742.0   \n",
            "\n",
            "   TAXIIN  CRSARRTIME  ARRTIME  ARRDELAY  CRSELAPSEDTIME  ACTUALELAPSEDTIME  \\\n",
            "0     4.0        1655   1652.0      -3.0            90.0               87.0   \n",
            "1    16.0        1426   1435.0       9.0           116.0              119.0   \n",
            "2     2.0        1500   1620.0      80.0           105.0              102.0   \n",
            "3     1.0        1950   1948.0      -2.0            85.0               83.0   \n",
            "4     5.0        1750   1747.0      -3.0           115.0              114.0   \n",
            "\n",
            "  CANCELLED DIVERTED   DISTANCE  \n",
            "0         F    False  580 miles  \n",
            "1     False        F  744 miles  \n",
            "2         F    False  718 miles  \n",
            "3         0        0  487 miles  \n",
            "4         F    False  744 miles  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g92ggCftW5q4",
        "outputId": "6bf28e3f-3045-4d41-e2cf-11b28efcb9b0"
      },
      "source": [
        "flights_df[\"FLIGHTDATE\"]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          20020101\n",
              "1          20020101\n",
              "2          20020101\n",
              "3          20020101\n",
              "4          20020103\n",
              "             ...   \n",
              "1191800    20130106\n",
              "1191801    20130106\n",
              "1191802    20130106\n",
              "1191803    20130106\n",
              "1191804    20130106\n",
              "Name: FLIGHTDATE, Length: 1191805, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C60YgZ8nW5q5",
        "outputId": "70cd2023-4851-4a40-8b89-dd84b1ca105a"
      },
      "source": [
        "pd.to_datetime(flights_df[\"FLIGHTDATE\"])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         1970-01-01 00:00:00.020020101\n",
              "1         1970-01-01 00:00:00.020020101\n",
              "2         1970-01-01 00:00:00.020020101\n",
              "3         1970-01-01 00:00:00.020020101\n",
              "4         1970-01-01 00:00:00.020020103\n",
              "                       ...             \n",
              "1191800   1970-01-01 00:00:00.020130106\n",
              "1191801   1970-01-01 00:00:00.020130106\n",
              "1191802   1970-01-01 00:00:00.020130106\n",
              "1191803   1970-01-01 00:00:00.020130106\n",
              "1191804   1970-01-01 00:00:00.020130106\n",
              "Name: FLIGHTDATE, Length: 1191805, dtype: datetime64[ns]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgwp7TAtW5q6"
      },
      "source": [
        "Uhhh... what happened there? Why are all our dates 1970-01-01 now?\n",
        "\n",
        "Well, it's because, as I mentioned, dates are internally stored as seconds (numbers). Our `FLIGHTDATE` column is also displaying the flight dates as numbers. Thus, when we run the `.to_datetime()` method, all of our dates are interpreted as POSIX time.\n",
        "\n",
        "One simple solution we can do to fix that is to explicitly specify our datetime format. Given the examples above, what do you think the date format is going to be?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR7te7pdW5q7",
        "outputId": "c41947d0-497e-456f-b3a2-845251deaf52"
      },
      "source": [
        "## Assign date_format\n",
        "date_format = \"%Y%m%d\"\n",
        "# date_format = \"%d-%m-%Y\"\n",
        "pd.to_datetime(flights_df[\"FLIGHTDATE\"], format=date_format)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         2002-01-01\n",
              "1         2002-01-01\n",
              "2         2002-01-01\n",
              "3         2002-01-01\n",
              "4         2002-01-03\n",
              "             ...    \n",
              "1191800   2013-01-06\n",
              "1191801   2013-01-06\n",
              "1191802   2013-01-06\n",
              "1191803   2013-01-06\n",
              "1191804   2013-01-06\n",
              "Name: FLIGHTDATE, Length: 1191805, dtype: datetime64[ns]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBtvxZYeW5q9"
      },
      "source": [
        "Better! Cool! Ok, so this solution was quite specific to the problem we had at hand. But in the real world you may often encounter mixed formats for dates in one dataframe. For example:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><b>Name</b></td>\n",
        "        <td><b>Date of Birth</b></td>\n",
        "        <td><b>Age</b></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>John</td>\n",
        "        <td>01/07/1995</td>\n",
        "        <td>25</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Jane</td>\n",
        "        <td>20-04-1992</td>\n",
        "        <td>28</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Mark</td>\n",
        "        <td>3rd January 1990</td>\n",
        "        <td>30</td>\n",
        "    </tr>\n",
        "    </table>\n",
        "    \n",
        "`.to_datetime()` once again comes at the rescue here! In the previous code cell, we explicitly set the date format (because of the unusual nature of the way this date was stored in the dataframe) - but more generally we can use `.to_datetime()` to automatically infer the format of each individual date.\n",
        "\n",
        "```python\n",
        "# errors='coerce' means we'll return NA rows for invalid dates\n",
        "df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], infer_datetime_format=True, errors='coerce') \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b85Dh1ZlW5q-"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Modify CRSDEPTIME and CRSARRTIME to be in a datetime format. Notice that the days might tick over on to the next day... Which column can you use to help you infer whether this could be the case?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "SnZsgbs7W5q_",
        "outputId": "bc6fbd89-018f-4bde-98f1-602b31aa34ca"
      },
      "source": [
        "flights_df = flights_df.convert_dtypes()\n",
        "flights_df.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TRANSACTIONID</th>\n",
              "      <th>FLIGHTDATE</th>\n",
              "      <th>AIRLINECODE</th>\n",
              "      <th>AIRLINENAME</th>\n",
              "      <th>TAILNUM</th>\n",
              "      <th>FLIGHTNUM</th>\n",
              "      <th>ORIGINAIRPORTCODE</th>\n",
              "      <th>ORIGAIRPORTNAME</th>\n",
              "      <th>ORIGINCITYNAME</th>\n",
              "      <th>ORIGINSTATE</th>\n",
              "      <th>ORIGINSTATENAME</th>\n",
              "      <th>DESTAIRPORTCODE</th>\n",
              "      <th>DESTAIRPORTNAME</th>\n",
              "      <th>DESTCITYNAME</th>\n",
              "      <th>DESTSTATE</th>\n",
              "      <th>DESTSTATENAME</th>\n",
              "      <th>CRSDEPTIME</th>\n",
              "      <th>DEPTIME</th>\n",
              "      <th>DEPDELAY</th>\n",
              "      <th>TAXIOUT</th>\n",
              "      <th>WHEELSOFF</th>\n",
              "      <th>WHEELSON</th>\n",
              "      <th>TAXIIN</th>\n",
              "      <th>CRSARRTIME</th>\n",
              "      <th>ARRTIME</th>\n",
              "      <th>ARRDELAY</th>\n",
              "      <th>CRSELAPSEDTIME</th>\n",
              "      <th>ACTUALELAPSEDTIME</th>\n",
              "      <th>CANCELLED</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>DISTANCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>54548800</td>\n",
              "      <td>20020101</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.: WN</td>\n",
              "      <td>N103@@</td>\n",
              "      <td>1425</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>DAL</td>\n",
              "      <td>DallasTX: Dallas Love Field</td>\n",
              "      <td>Dallas</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>1425</td>\n",
              "      <td>1425</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1433</td>\n",
              "      <td>1648</td>\n",
              "      <td>4</td>\n",
              "      <td>1655</td>\n",
              "      <td>1652</td>\n",
              "      <td>-3</td>\n",
              "      <td>90</td>\n",
              "      <td>87</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>580 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55872300</td>\n",
              "      <td>20020101</td>\n",
              "      <td>CO</td>\n",
              "      <td>Continental Air Lines Inc.: CO</td>\n",
              "      <td>N83872</td>\n",
              "      <td>150</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>IAH</td>\n",
              "      <td>HoustonTX: George Bush Intercontinental/Houston</td>\n",
              "      <td>Houston</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>1130</td>\n",
              "      <td>1136</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>1148</td>\n",
              "      <td>1419</td>\n",
              "      <td>16</td>\n",
              "      <td>1426</td>\n",
              "      <td>1435</td>\n",
              "      <td>9</td>\n",
              "      <td>116</td>\n",
              "      <td>119</td>\n",
              "      <td>False</td>\n",
              "      <td>F</td>\n",
              "      <td>744 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54388800</td>\n",
              "      <td>20020101</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.: WN</td>\n",
              "      <td>N334@@</td>\n",
              "      <td>249</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>MCI</td>\n",
              "      <td>Kansas CityMO: Kansas City International</td>\n",
              "      <td>Kansas City</td>\n",
              "      <td>MO</td>\n",
              "      <td>Missouri</td>\n",
              "      <td>1215</td>\n",
              "      <td>1338</td>\n",
              "      <td>83</td>\n",
              "      <td>7</td>\n",
              "      <td>1345</td>\n",
              "      <td>1618</td>\n",
              "      <td>2</td>\n",
              "      <td>1500</td>\n",
              "      <td>1620</td>\n",
              "      <td>80</td>\n",
              "      <td>105</td>\n",
              "      <td>102</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>718 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54486500</td>\n",
              "      <td>20020101</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.: WN</td>\n",
              "      <td>N699@@</td>\n",
              "      <td>902</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>LAS</td>\n",
              "      <td>Las VegasNV: McCarran International</td>\n",
              "      <td>Las Vegas</td>\n",
              "      <td>NV</td>\n",
              "      <td>Nevada</td>\n",
              "      <td>1925</td>\n",
              "      <td>1925</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1930</td>\n",
              "      <td>1947</td>\n",
              "      <td>1</td>\n",
              "      <td>1950</td>\n",
              "      <td>1948</td>\n",
              "      <td>-2</td>\n",
              "      <td>85</td>\n",
              "      <td>83</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>487 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55878700</td>\n",
              "      <td>20020103</td>\n",
              "      <td>CO</td>\n",
              "      <td>Continental Air Lines Inc.: CO</td>\n",
              "      <td>N58606</td>\n",
              "      <td>234</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>IAH</td>\n",
              "      <td>HoustonTX: George Bush Intercontinental/Houston</td>\n",
              "      <td>Houston</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>1455</td>\n",
              "      <td>1453</td>\n",
              "      <td>-2</td>\n",
              "      <td>11</td>\n",
              "      <td>1504</td>\n",
              "      <td>1742</td>\n",
              "      <td>5</td>\n",
              "      <td>1750</td>\n",
              "      <td>1747</td>\n",
              "      <td>-3</td>\n",
              "      <td>115</td>\n",
              "      <td>114</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>744 miles</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TRANSACTIONID  FLIGHTDATE AIRLINECODE                     AIRLINENAME  \\\n",
              "0       54548800    20020101          WN      Southwest Airlines Co.: WN   \n",
              "1       55872300    20020101          CO  Continental Air Lines Inc.: CO   \n",
              "2       54388800    20020101          WN      Southwest Airlines Co.: WN   \n",
              "3       54486500    20020101          WN      Southwest Airlines Co.: WN   \n",
              "4       55878700    20020103          CO  Continental Air Lines Inc.: CO   \n",
              "\n",
              "  TAILNUM  FLIGHTNUM ORIGINAIRPORTCODE  \\\n",
              "0  N103@@       1425               ABQ   \n",
              "1  N83872        150               ABQ   \n",
              "2  N334@@        249               ABQ   \n",
              "3  N699@@        902               ABQ   \n",
              "4  N58606        234               ABQ   \n",
              "\n",
              "                                    ORIGAIRPORTNAME ORIGINCITYNAME  \\\n",
              "0  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "1  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "2  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "3  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "4  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "\n",
              "  ORIGINSTATE ORIGINSTATENAME DESTAIRPORTCODE  \\\n",
              "0          NM      New Mexico             DAL   \n",
              "1          NM      New Mexico             IAH   \n",
              "2          NM      New Mexico             MCI   \n",
              "3          NM      New Mexico             LAS   \n",
              "4          NM      New Mexico             IAH   \n",
              "\n",
              "                                   DESTAIRPORTNAME DESTCITYNAME DESTSTATE  \\\n",
              "0                      DallasTX: Dallas Love Field       Dallas        TX   \n",
              "1  HoustonTX: George Bush Intercontinental/Houston      Houston        TX   \n",
              "2         Kansas CityMO: Kansas City International  Kansas City        MO   \n",
              "3              Las VegasNV: McCarran International    Las Vegas        NV   \n",
              "4  HoustonTX: George Bush Intercontinental/Houston      Houston        TX   \n",
              "\n",
              "  DESTSTATENAME  CRSDEPTIME  DEPTIME  DEPDELAY  TAXIOUT  WHEELSOFF  WHEELSON  \\\n",
              "0         Texas        1425     1425         0        8       1433      1648   \n",
              "1         Texas        1130     1136         6       12       1148      1419   \n",
              "2      Missouri        1215     1338        83        7       1345      1618   \n",
              "3        Nevada        1925     1925         0        5       1930      1947   \n",
              "4         Texas        1455     1453        -2       11       1504      1742   \n",
              "\n",
              "   TAXIIN  CRSARRTIME  ARRTIME  ARRDELAY  CRSELAPSEDTIME  ACTUALELAPSEDTIME  \\\n",
              "0       4        1655     1652        -3              90                 87   \n",
              "1      16        1426     1435         9             116                119   \n",
              "2       2        1500     1620        80             105                102   \n",
              "3       1        1950     1948        -2              85                 83   \n",
              "4       5        1750     1747        -3             115                114   \n",
              "\n",
              "  CANCELLED DIVERTED   DISTANCE  \n",
              "0         F    False  580 miles  \n",
              "1     False        F  744 miles  \n",
              "2         F    False  718 miles  \n",
              "3         0        0  487 miles  \n",
              "4         F    False  744 miles  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XvUXvtRW5rI",
        "outputId": "6bdf72c4-d403-476f-9073-04492dc8ee77"
      },
      "source": [
        "## Create a new variable CRSDEPDATETIME which concatenates the FLIGHTDATE and CRSDEPTIME columns\n",
        "# If you're unsure how... try googling it\n",
        "# You'll probably also need to type convert the relevant columns\n",
        "flights_df[\"FLIGHTDATE\"] = pd.to_datetime(flights_df[\"FLIGHTDATE\"], format=\"%Y%m%d\")\n",
        "CRSDEPDATETIME = flights_df[\"FLIGHTDATE\"].astype(\"str\") + \" \" + flights_df[\"CRSDEPTIME\"].astype(\"str\")\n",
        "CRSDEPDATETIME"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          2002-01-01 1425\n",
              "1          2002-01-01 1130\n",
              "2          2002-01-01 1215\n",
              "3          2002-01-01 1925\n",
              "4          2002-01-03 1455\n",
              "                ...       \n",
              "1191800    2013-01-06 1357\n",
              "1191801    2013-01-06 2150\n",
              "1191802    2013-01-06 1617\n",
              "1191803    2013-01-06 1516\n",
              "1191804    2013-01-06 1452\n",
              "Length: 1191805, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "cWBrV30HW5rK",
        "outputId": "7674b1b5-056c-4bde-9cd2-b6dfa2215754"
      },
      "source": [
        "## Convert CRSDEPDATETIME to a datetime object and overwrite the CRSDEPTIME with the new series\n",
        "flights_df[\"CRSDEPTIME\"] = pd.to_datetime(CRSDEPDATETIME, infer_datetime_format=True, errors='coerce')\n",
        "flights_df.head()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TRANSACTIONID</th>\n",
              "      <th>FLIGHTDATE</th>\n",
              "      <th>AIRLINECODE</th>\n",
              "      <th>AIRLINENAME</th>\n",
              "      <th>TAILNUM</th>\n",
              "      <th>FLIGHTNUM</th>\n",
              "      <th>ORIGINAIRPORTCODE</th>\n",
              "      <th>ORIGAIRPORTNAME</th>\n",
              "      <th>ORIGINCITYNAME</th>\n",
              "      <th>ORIGINSTATE</th>\n",
              "      <th>ORIGINSTATENAME</th>\n",
              "      <th>DESTAIRPORTCODE</th>\n",
              "      <th>DESTAIRPORTNAME</th>\n",
              "      <th>DESTCITYNAME</th>\n",
              "      <th>DESTSTATE</th>\n",
              "      <th>DESTSTATENAME</th>\n",
              "      <th>CRSDEPTIME</th>\n",
              "      <th>DEPTIME</th>\n",
              "      <th>DEPDELAY</th>\n",
              "      <th>TAXIOUT</th>\n",
              "      <th>WHEELSOFF</th>\n",
              "      <th>WHEELSON</th>\n",
              "      <th>TAXIIN</th>\n",
              "      <th>CRSARRTIME</th>\n",
              "      <th>ARRTIME</th>\n",
              "      <th>ARRDELAY</th>\n",
              "      <th>CRSELAPSEDTIME</th>\n",
              "      <th>ACTUALELAPSEDTIME</th>\n",
              "      <th>CANCELLED</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>DISTANCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>54548800</td>\n",
              "      <td>2002-01-01</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.: WN</td>\n",
              "      <td>N103@@</td>\n",
              "      <td>1425</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>DAL</td>\n",
              "      <td>DallasTX: Dallas Love Field</td>\n",
              "      <td>Dallas</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>2002-01-01 14:25:00</td>\n",
              "      <td>1425</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1433</td>\n",
              "      <td>1648</td>\n",
              "      <td>4</td>\n",
              "      <td>1655</td>\n",
              "      <td>1652</td>\n",
              "      <td>-3</td>\n",
              "      <td>90</td>\n",
              "      <td>87</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>580 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55872300</td>\n",
              "      <td>2002-01-01</td>\n",
              "      <td>CO</td>\n",
              "      <td>Continental Air Lines Inc.: CO</td>\n",
              "      <td>N83872</td>\n",
              "      <td>150</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>IAH</td>\n",
              "      <td>HoustonTX: George Bush Intercontinental/Houston</td>\n",
              "      <td>Houston</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>2002-01-01 11:30:00</td>\n",
              "      <td>1136</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>1148</td>\n",
              "      <td>1419</td>\n",
              "      <td>16</td>\n",
              "      <td>1426</td>\n",
              "      <td>1435</td>\n",
              "      <td>9</td>\n",
              "      <td>116</td>\n",
              "      <td>119</td>\n",
              "      <td>False</td>\n",
              "      <td>F</td>\n",
              "      <td>744 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54388800</td>\n",
              "      <td>2002-01-01</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.: WN</td>\n",
              "      <td>N334@@</td>\n",
              "      <td>249</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>MCI</td>\n",
              "      <td>Kansas CityMO: Kansas City International</td>\n",
              "      <td>Kansas City</td>\n",
              "      <td>MO</td>\n",
              "      <td>Missouri</td>\n",
              "      <td>2002-01-01 12:15:00</td>\n",
              "      <td>1338</td>\n",
              "      <td>83</td>\n",
              "      <td>7</td>\n",
              "      <td>1345</td>\n",
              "      <td>1618</td>\n",
              "      <td>2</td>\n",
              "      <td>1500</td>\n",
              "      <td>1620</td>\n",
              "      <td>80</td>\n",
              "      <td>105</td>\n",
              "      <td>102</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>718 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54486500</td>\n",
              "      <td>2002-01-01</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.: WN</td>\n",
              "      <td>N699@@</td>\n",
              "      <td>902</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>LAS</td>\n",
              "      <td>Las VegasNV: McCarran International</td>\n",
              "      <td>Las Vegas</td>\n",
              "      <td>NV</td>\n",
              "      <td>Nevada</td>\n",
              "      <td>2002-01-01 19:25:00</td>\n",
              "      <td>1925</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1930</td>\n",
              "      <td>1947</td>\n",
              "      <td>1</td>\n",
              "      <td>1950</td>\n",
              "      <td>1948</td>\n",
              "      <td>-2</td>\n",
              "      <td>85</td>\n",
              "      <td>83</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>487 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55878700</td>\n",
              "      <td>2002-01-03</td>\n",
              "      <td>CO</td>\n",
              "      <td>Continental Air Lines Inc.: CO</td>\n",
              "      <td>N58606</td>\n",
              "      <td>234</td>\n",
              "      <td>ABQ</td>\n",
              "      <td>AlbuquerqueNM: Albuquerque International Sunport</td>\n",
              "      <td>Albuquerque</td>\n",
              "      <td>NM</td>\n",
              "      <td>New Mexico</td>\n",
              "      <td>IAH</td>\n",
              "      <td>HoustonTX: George Bush Intercontinental/Houston</td>\n",
              "      <td>Houston</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>2002-01-03 14:55:00</td>\n",
              "      <td>1453</td>\n",
              "      <td>-2</td>\n",
              "      <td>11</td>\n",
              "      <td>1504</td>\n",
              "      <td>1742</td>\n",
              "      <td>5</td>\n",
              "      <td>1750</td>\n",
              "      <td>1747</td>\n",
              "      <td>-3</td>\n",
              "      <td>115</td>\n",
              "      <td>114</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>744 miles</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TRANSACTIONID FLIGHTDATE AIRLINECODE                     AIRLINENAME  \\\n",
              "0       54548800 2002-01-01          WN      Southwest Airlines Co.: WN   \n",
              "1       55872300 2002-01-01          CO  Continental Air Lines Inc.: CO   \n",
              "2       54388800 2002-01-01          WN      Southwest Airlines Co.: WN   \n",
              "3       54486500 2002-01-01          WN      Southwest Airlines Co.: WN   \n",
              "4       55878700 2002-01-03          CO  Continental Air Lines Inc.: CO   \n",
              "\n",
              "  TAILNUM  FLIGHTNUM ORIGINAIRPORTCODE  \\\n",
              "0  N103@@       1425               ABQ   \n",
              "1  N83872        150               ABQ   \n",
              "2  N334@@        249               ABQ   \n",
              "3  N699@@        902               ABQ   \n",
              "4  N58606        234               ABQ   \n",
              "\n",
              "                                    ORIGAIRPORTNAME ORIGINCITYNAME  \\\n",
              "0  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "1  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "2  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "3  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "4  AlbuquerqueNM: Albuquerque International Sunport    Albuquerque   \n",
              "\n",
              "  ORIGINSTATE ORIGINSTATENAME DESTAIRPORTCODE  \\\n",
              "0          NM      New Mexico             DAL   \n",
              "1          NM      New Mexico             IAH   \n",
              "2          NM      New Mexico             MCI   \n",
              "3          NM      New Mexico             LAS   \n",
              "4          NM      New Mexico             IAH   \n",
              "\n",
              "                                   DESTAIRPORTNAME DESTCITYNAME DESTSTATE  \\\n",
              "0                      DallasTX: Dallas Love Field       Dallas        TX   \n",
              "1  HoustonTX: George Bush Intercontinental/Houston      Houston        TX   \n",
              "2         Kansas CityMO: Kansas City International  Kansas City        MO   \n",
              "3              Las VegasNV: McCarran International    Las Vegas        NV   \n",
              "4  HoustonTX: George Bush Intercontinental/Houston      Houston        TX   \n",
              "\n",
              "  DESTSTATENAME          CRSDEPTIME  DEPTIME  DEPDELAY  TAXIOUT  WHEELSOFF  \\\n",
              "0         Texas 2002-01-01 14:25:00     1425         0        8       1433   \n",
              "1         Texas 2002-01-01 11:30:00     1136         6       12       1148   \n",
              "2      Missouri 2002-01-01 12:15:00     1338        83        7       1345   \n",
              "3        Nevada 2002-01-01 19:25:00     1925         0        5       1930   \n",
              "4         Texas 2002-01-03 14:55:00     1453        -2       11       1504   \n",
              "\n",
              "   WHEELSON  TAXIIN  CRSARRTIME  ARRTIME  ARRDELAY  CRSELAPSEDTIME  \\\n",
              "0      1648       4        1655     1652        -3              90   \n",
              "1      1419      16        1426     1435         9             116   \n",
              "2      1618       2        1500     1620        80             105   \n",
              "3      1947       1        1950     1948        -2              85   \n",
              "4      1742       5        1750     1747        -3             115   \n",
              "\n",
              "   ACTUALELAPSEDTIME CANCELLED DIVERTED   DISTANCE  \n",
              "0                 87         F    False  580 miles  \n",
              "1                119     False        F  744 miles  \n",
              "2                102         F    False  718 miles  \n",
              "3                 83         0        0  487 miles  \n",
              "4                114         F    False  744 miles  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrclUtAUW5rK",
        "outputId": "7974af39-c8d5-4a10-9f03-b9f3f0cc97e8"
      },
      "source": [
        "# Now we want to convert CRSARRTIME to a datetime object.\n",
        "# What would be the issue with just doing the same trick as above and using FLIGHTDATE and appending the CRSARRTIME to it?\n",
        "# So we know that we need to keep the answer to the above question in mind when trying to construct the new datetime object\n",
        "\n",
        "# I found this stackoverflow link to guide me through how to solve my problem:\n",
        "# https://stackoverflow.com/questions/34519536/convert-integer-series-to-timedelta-in-pandas\n",
        "# What do you think I googled to find this page?\n",
        "# You may need to research the method the answer provides to find the correct arguments to pass in\n",
        "\n",
        "## Assign time_to_shift using the timedelta method\n",
        "# I imagine you will run into a type error. Take a couple of minutes to see if you can find how to resolve the issue\n",
        "# Otherwise: https://stackoverflow.com/a/21290084/3297011 should provide you with the conceptual solution\n",
        "\n",
        "time_to_shift = pd.to_timedelta(flights_df[\"CRSELAPSEDTIME\"].astype(\"float64\"), unit=\"minute\")\n",
        "\n",
        "## Assign CRSARRDATETIME to CRSDEPTIME + time_to_shift\n",
        "\n",
        "CRSARRDATETIME = flights_df[\"CRSDEPTIME\"] + time_to_shift\n",
        "CRSARRDATETIME\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         2002-01-01 15:55:00\n",
              "1         2002-01-01 13:26:00\n",
              "2         2002-01-01 14:00:00\n",
              "3         2002-01-01 20:50:00\n",
              "4         2002-01-03 16:50:00\n",
              "                  ...        \n",
              "1191800   2013-01-06 16:23:00\n",
              "1191801   2013-01-07 00:21:00\n",
              "1191802   2013-01-06 18:50:00\n",
              "1191803   2013-01-06 16:58:00\n",
              "1191804   2013-01-06 16:09:00\n",
              "Length: 1191805, dtype: datetime64[ns]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "I4VxOfV2W5rK",
        "outputId": "df71c6fa-cf57-4cb5-ac14-e6e8461bb68d"
      },
      "source": [
        "flights_df.tail()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TRANSACTIONID</th>\n",
              "      <th>FLIGHTDATE</th>\n",
              "      <th>AIRLINECODE</th>\n",
              "      <th>AIRLINENAME</th>\n",
              "      <th>TAILNUM</th>\n",
              "      <th>FLIGHTNUM</th>\n",
              "      <th>ORIGINAIRPORTCODE</th>\n",
              "      <th>ORIGAIRPORTNAME</th>\n",
              "      <th>ORIGINCITYNAME</th>\n",
              "      <th>ORIGINSTATE</th>\n",
              "      <th>ORIGINSTATENAME</th>\n",
              "      <th>DESTAIRPORTCODE</th>\n",
              "      <th>DESTAIRPORTNAME</th>\n",
              "      <th>DESTCITYNAME</th>\n",
              "      <th>DESTSTATE</th>\n",
              "      <th>DESTSTATENAME</th>\n",
              "      <th>CRSDEPTIME</th>\n",
              "      <th>DEPTIME</th>\n",
              "      <th>DEPDELAY</th>\n",
              "      <th>TAXIOUT</th>\n",
              "      <th>WHEELSOFF</th>\n",
              "      <th>WHEELSON</th>\n",
              "      <th>TAXIIN</th>\n",
              "      <th>CRSARRTIME</th>\n",
              "      <th>ARRTIME</th>\n",
              "      <th>ARRDELAY</th>\n",
              "      <th>CRSELAPSEDTIME</th>\n",
              "      <th>ACTUALELAPSEDTIME</th>\n",
              "      <th>CANCELLED</th>\n",
              "      <th>DIVERTED</th>\n",
              "      <th>DISTANCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1191800</th>\n",
              "      <td>126750200</td>\n",
              "      <td>2013-01-06</td>\n",
              "      <td>EV</td>\n",
              "      <td>ExpressJet Airlines Inc.: EV</td>\n",
              "      <td>N683BR</td>\n",
              "      <td>5272</td>\n",
              "      <td>ATL</td>\n",
              "      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>GA</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>DAL</td>\n",
              "      <td>DallasTX: Dallas Love Field</td>\n",
              "      <td>Dallas</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>2013-01-06 13:57:00</td>\n",
              "      <td>1348</td>\n",
              "      <td>-9</td>\n",
              "      <td>22</td>\n",
              "      <td>1410</td>\n",
              "      <td>1500</td>\n",
              "      <td>3</td>\n",
              "      <td>1523</td>\n",
              "      <td>1503</td>\n",
              "      <td>-20</td>\n",
              "      <td>146</td>\n",
              "      <td>135</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>721 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1191801</th>\n",
              "      <td>127294500</td>\n",
              "      <td>2013-01-06</td>\n",
              "      <td>DL</td>\n",
              "      <td>Delta Air Lines Inc.: DL</td>\n",
              "      <td>N949DL</td>\n",
              "      <td>1711</td>\n",
              "      <td>ATL</td>\n",
              "      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>GA</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>DFW</td>\n",
              "      <td>Dallas/Fort WorthTX: Dallas/Fort Worth Interna...</td>\n",
              "      <td>Dallas/Fort Worth</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>2013-01-06 21:50:00</td>\n",
              "      <td>2147</td>\n",
              "      <td>-3</td>\n",
              "      <td>23</td>\n",
              "      <td>2210</td>\n",
              "      <td>2307</td>\n",
              "      <td>10</td>\n",
              "      <td>2321</td>\n",
              "      <td>2317</td>\n",
              "      <td>-4</td>\n",
              "      <td>151</td>\n",
              "      <td>150</td>\n",
              "      <td>False</td>\n",
              "      <td>F</td>\n",
              "      <td>731 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1191802</th>\n",
              "      <td>127294900</td>\n",
              "      <td>2013-01-06</td>\n",
              "      <td>DL</td>\n",
              "      <td>Delta Air Lines Inc.: DL</td>\n",
              "      <td>N907DE</td>\n",
              "      <td>1810</td>\n",
              "      <td>ATL</td>\n",
              "      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>GA</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>DFW</td>\n",
              "      <td>Dallas/Fort WorthTX: Dallas/Fort Worth Interna...</td>\n",
              "      <td>Dallas/Fort Worth</td>\n",
              "      <td>TX</td>\n",
              "      <td>Texas</td>\n",
              "      <td>2013-01-06 16:17:00</td>\n",
              "      <td>1617</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>1635</td>\n",
              "      <td>1728</td>\n",
              "      <td>9</td>\n",
              "      <td>1750</td>\n",
              "      <td>1737</td>\n",
              "      <td>-13</td>\n",
              "      <td>153</td>\n",
              "      <td>140</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>731 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1191803</th>\n",
              "      <td>126594900</td>\n",
              "      <td>2013-01-06</td>\n",
              "      <td>EV</td>\n",
              "      <td>ExpressJet Airlines Inc.: EV</td>\n",
              "      <td>N855AS</td>\n",
              "      <td>5208</td>\n",
              "      <td>ATL</td>\n",
              "      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>GA</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>FWA</td>\n",
              "      <td>Fort WayneIN: Fort Wayne International</td>\n",
              "      <td>Fort Wayne</td>\n",
              "      <td>IN</td>\n",
              "      <td>Indiana</td>\n",
              "      <td>2013-01-06 15:16:00</td>\n",
              "      <td>1514</td>\n",
              "      <td>-2</td>\n",
              "      <td>21</td>\n",
              "      <td>1535</td>\n",
              "      <td>1651</td>\n",
              "      <td>4</td>\n",
              "      <td>1658</td>\n",
              "      <td>1655</td>\n",
              "      <td>-3</td>\n",
              "      <td>102</td>\n",
              "      <td>101</td>\n",
              "      <td>False</td>\n",
              "      <td>F</td>\n",
              "      <td>508 miles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1191804</th>\n",
              "      <td>126620300</td>\n",
              "      <td>2013-01-06</td>\n",
              "      <td>EV</td>\n",
              "      <td>ExpressJet Airlines Inc.: EV</td>\n",
              "      <td>N138EV</td>\n",
              "      <td>5549</td>\n",
              "      <td>ATL</td>\n",
              "      <td>AtlantaGA: Hartsfield-Jackson Atlanta Internat...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>GA</td>\n",
              "      <td>Georgia</td>\n",
              "      <td>GSO</td>\n",
              "      <td>Greensboro/High PointNC: Piedmont Triad Intern...</td>\n",
              "      <td>Greensboro/High Point</td>\n",
              "      <td>NC</td>\n",
              "      <td>North Carolina</td>\n",
              "      <td>2013-01-06 14:52:00</td>\n",
              "      <td>1458</td>\n",
              "      <td>6</td>\n",
              "      <td>27</td>\n",
              "      <td>1525</td>\n",
              "      <td>1611</td>\n",
              "      <td>4</td>\n",
              "      <td>1609</td>\n",
              "      <td>1615</td>\n",
              "      <td>6</td>\n",
              "      <td>77</td>\n",
              "      <td>77</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>306 miles</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         TRANSACTIONID FLIGHTDATE AIRLINECODE                   AIRLINENAME  \\\n",
              "1191800      126750200 2013-01-06          EV  ExpressJet Airlines Inc.: EV   \n",
              "1191801      127294500 2013-01-06          DL      Delta Air Lines Inc.: DL   \n",
              "1191802      127294900 2013-01-06          DL      Delta Air Lines Inc.: DL   \n",
              "1191803      126594900 2013-01-06          EV  ExpressJet Airlines Inc.: EV   \n",
              "1191804      126620300 2013-01-06          EV  ExpressJet Airlines Inc.: EV   \n",
              "\n",
              "        TAILNUM  FLIGHTNUM ORIGINAIRPORTCODE  \\\n",
              "1191800  N683BR       5272               ATL   \n",
              "1191801  N949DL       1711               ATL   \n",
              "1191802  N907DE       1810               ATL   \n",
              "1191803  N855AS       5208               ATL   \n",
              "1191804  N138EV       5549               ATL   \n",
              "\n",
              "                                           ORIGAIRPORTNAME ORIGINCITYNAME  \\\n",
              "1191800  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n",
              "1191801  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n",
              "1191802  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n",
              "1191803  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n",
              "1191804  AtlantaGA: Hartsfield-Jackson Atlanta Internat...        Atlanta   \n",
              "\n",
              "        ORIGINSTATE ORIGINSTATENAME DESTAIRPORTCODE  \\\n",
              "1191800          GA         Georgia             DAL   \n",
              "1191801          GA         Georgia             DFW   \n",
              "1191802          GA         Georgia             DFW   \n",
              "1191803          GA         Georgia             FWA   \n",
              "1191804          GA         Georgia             GSO   \n",
              "\n",
              "                                           DESTAIRPORTNAME  \\\n",
              "1191800                        DallasTX: Dallas Love Field   \n",
              "1191801  Dallas/Fort WorthTX: Dallas/Fort Worth Interna...   \n",
              "1191802  Dallas/Fort WorthTX: Dallas/Fort Worth Interna...   \n",
              "1191803             Fort WayneIN: Fort Wayne International   \n",
              "1191804  Greensboro/High PointNC: Piedmont Triad Intern...   \n",
              "\n",
              "                  DESTCITYNAME DESTSTATE   DESTSTATENAME          CRSDEPTIME  \\\n",
              "1191800                 Dallas        TX           Texas 2013-01-06 13:57:00   \n",
              "1191801      Dallas/Fort Worth        TX           Texas 2013-01-06 21:50:00   \n",
              "1191802      Dallas/Fort Worth        TX           Texas 2013-01-06 16:17:00   \n",
              "1191803             Fort Wayne        IN         Indiana 2013-01-06 15:16:00   \n",
              "1191804  Greensboro/High Point        NC  North Carolina 2013-01-06 14:52:00   \n",
              "\n",
              "         DEPTIME  DEPDELAY  TAXIOUT  WHEELSOFF  WHEELSON  TAXIIN  CRSARRTIME  \\\n",
              "1191800     1348        -9       22       1410      1500       3        1523   \n",
              "1191801     2147        -3       23       2210      2307      10        2321   \n",
              "1191802     1617         0       18       1635      1728       9        1750   \n",
              "1191803     1514        -2       21       1535      1651       4        1658   \n",
              "1191804     1458         6       27       1525      1611       4        1609   \n",
              "\n",
              "         ARRTIME  ARRDELAY  CRSELAPSEDTIME  ACTUALELAPSEDTIME CANCELLED  \\\n",
              "1191800     1503       -20             146                135         0   \n",
              "1191801     2317        -4             151                150     False   \n",
              "1191802     1737       -13             153                140         F   \n",
              "1191803     1655        -3             102                101     False   \n",
              "1191804     1615         6              77                 77     False   \n",
              "\n",
              "        DIVERTED   DISTANCE  \n",
              "1191800        0  721 miles  \n",
              "1191801        F  731 miles  \n",
              "1191802    False  731 miles  \n",
              "1191803        F  508 miles  \n",
              "1191804    False  306 miles  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTu_4HijW5rL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi_v-5TnW5rL"
      },
      "source": [
        "Interesting!! Take a look at these results and `CRSARRTIME` - what do you notice? Looks like CRSARRTIME has offsets here and there. Why do you think this is?\n",
        "\n",
        "It occurs because the destinations have different timezones than the departure city/state. As data scientists we have to ensure that manipulations to our data maintains its correctness and integrity.\n",
        "\n",
        "I won't overwrite the CRSARRTIME variable here but have a think about how you could correctly modify CRSARRTIME to be a datetime object. Click the arrow below to reveal the answer:\n",
        "\n",
        "<details>\n",
        "    <summary><b>> How I would modify CRSARRTIME</b></summary>\n",
        "    <ol>\n",
        "        <li>Build dictionary of US state timezone offsets. I would probably start the dictionary the 'earliest' state we have in the dataframe (e.g. if Hawai is present, then I'd use Hawaiian time (UTC-10) as the 0 offset). Every other state would have a value which is relative to the the 0 offset (e.g. New York's offset would be +5).</li>\n",
        "        <li>We know the origin and departure states, so the only thing left to do now is add the offset to the above <code>time_to_shift</code> variable we calculated. This seems trivial. We take the difference in offsets between the origin state and the destination state and add it to <code>time_to_shift</code>.</li>\n",
        "        <li>Use <code>time_to_shift</code> as above!</li>\n",
        "    </ol>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqzT7inXW5rL"
      },
      "source": [
        "## Cross Field Validation\n",
        "\n",
        "What does it meant to check the integrity of our data? Essentially, we need to be aware that a column of data we're seeing is consistent based on some other columns of data. We half handedly recognised and discovered an example of where we learnt a fact about one of the variables during the previous exercise. This is what **cross field validation** investigates. Before expanding on some of the cross field checks on this dataset, I will provide a slightly more trivial example to demonstrate where not performing such checks could skew analysis:\n",
        "\n",
        "The dummy table below shows entries of some student finance undergraduate (U.G) and postgraduate (P.G) loan holders. The dataset consists of a loan holder's name, date of birth (D.O.B), current age (or deceased age if relevant), whether they are deceased or not, their U.G and P.G loan amounts, and the total amount that they owe - which should be the summation of the previous two fields. In the table below, I have italicised the questionable fields.\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><b>Name</b></td>\n",
        "        <td><b>D.O.B</b></td>\n",
        "        <td><b>Age</b></td>\n",
        "        <td><b>Deceased</b></td>\n",
        "        <td><b>U.G Loan (£)</b></td>\n",
        "        <td><b>P.G Loan (£)</b></td>\n",
        "        <td><b>Total Loan (£)</b></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Idaline</td>\n",
        "        <td>1971-04-27</td>\n",
        "        <td>49</td>\n",
        "        <td>F</td>\n",
        "        <td>24100</td>\n",
        "        <td>11900</td>\n",
        "        <td>36000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Freddie</td>\n",
        "        <td>1962-12-27</td>\n",
        "        <td>57</td>\n",
        "        <td>F</td>\n",
        "        <td>26600</td>\n",
        "        <td>12600</td>\n",
        "        <td>39200</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Debee</td>\n",
        "        <td>1970-11-19</td>\n",
        "        <td>49</td>\n",
        "        <td>F</td>\n",
        "        <td>32400</td>\n",
        "        <td>97000</td>\n",
        "        <td><i>42100</i></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Joyann</td>\n",
        "        <td>1957-01-24</td>\n",
        "        <td><i>41</i></td>\n",
        "        <td>T</td>\n",
        "        <td>24400</td>\n",
        "        <td>11500</td>\n",
        "        <td>35900</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Ajay</td>\n",
        "        <td>1960-05-12</td>\n",
        "        <td><i>50</i></td>\n",
        "        <td>F</td>\n",
        "        <td>25500</td>\n",
        "        <td>18800</td>\n",
        "        <td>44300</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Emelia</td>\n",
        "        <td>1957-11-23</td>\n",
        "        <td><i>57</i></td>\n",
        "        <td>T</td>\n",
        "        <td>34000</td>\n",
        "        <td>17500</td>\n",
        "        <td><i>0</i></td>\n",
        "    </tr>\n",
        "            \n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "8KB6MElfW5rM",
        "outputId": "719295e4-af4d-46a2-d7e2-54e8345ffe1a"
      },
      "source": [
        "html_table = \"\"\"\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><b>Name</b></td>\n",
        "        <td><b>D.O.B</b></td>\n",
        "        <td><b>Age</b></td>\n",
        "        <td><b>Deceased</b></td>\n",
        "        <td><b>U.G Loan (£)</b></td>\n",
        "        <td><b>P.G Loan (£)</b></td>\n",
        "        <td><b>Total Loan (£)</b></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Idaline</td>\n",
        "        <td>19710427</td>\n",
        "        <td>50</td>\n",
        "        <td>F</td>\n",
        "        <td>24100</td>\n",
        "        <td>11900</td>\n",
        "        <td>36000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Freddie</td>\n",
        "        <td>19621227</td>\n",
        "        <td>58</td>\n",
        "        <td>F</td>\n",
        "        <td>26600</td>\n",
        "        <td>12600</td>\n",
        "        <td>39200</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Debee</td>\n",
        "        <td>19701119</td>\n",
        "        <td>49</td>\n",
        "        <td>F</td>\n",
        "        <td>32400</td>\n",
        "        <td>97000</td>\n",
        "        <td><i>42100</i></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Joyann</td>\n",
        "        <td>19570124</td>\n",
        "        <td><i>41</i></td>\n",
        "        <td>T</td>\n",
        "        <td>24400</td>\n",
        "        <td>11500</td>\n",
        "        <td>35900</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Ajay</td>\n",
        "        <td>19600512</td>\n",
        "        <td><i>50</i></td>\n",
        "        <td>F</td>\n",
        "        <td>25500</td>\n",
        "        <td>18800</td>\n",
        "        <td>44300</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Emelia</td>\n",
        "        <td>19571123</td>\n",
        "        <td><i>57</i></td>\n",
        "        <td>T</td>\n",
        "        <td>34000</td>\n",
        "        <td>17500</td>\n",
        "        <td><i>0</i></td>\n",
        "    </tr>\n",
        "            \n",
        "</table>\n",
        "\"\"\"\n",
        "\n",
        "html_df = pd.read_html(html_table, header=0)[0]\n",
        "html_df"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>D.O.B</th>\n",
              "      <th>Age</th>\n",
              "      <th>Deceased</th>\n",
              "      <th>U.G Loan (£)</th>\n",
              "      <th>P.G Loan (£)</th>\n",
              "      <th>Total Loan (£)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Idaline</td>\n",
              "      <td>19710427</td>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "      <td>24100</td>\n",
              "      <td>11900</td>\n",
              "      <td>36000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Freddie</td>\n",
              "      <td>19621227</td>\n",
              "      <td>58</td>\n",
              "      <td>F</td>\n",
              "      <td>26600</td>\n",
              "      <td>12600</td>\n",
              "      <td>39200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Debee</td>\n",
              "      <td>19701119</td>\n",
              "      <td>49</td>\n",
              "      <td>F</td>\n",
              "      <td>32400</td>\n",
              "      <td>97000</td>\n",
              "      <td>42100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Joyann</td>\n",
              "      <td>19570124</td>\n",
              "      <td>41</td>\n",
              "      <td>T</td>\n",
              "      <td>24400</td>\n",
              "      <td>11500</td>\n",
              "      <td>35900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ajay</td>\n",
              "      <td>19600512</td>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "      <td>25500</td>\n",
              "      <td>18800</td>\n",
              "      <td>44300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Emelia</td>\n",
              "      <td>19571123</td>\n",
              "      <td>57</td>\n",
              "      <td>T</td>\n",
              "      <td>34000</td>\n",
              "      <td>17500</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Name     D.O.B  Age Deceased  U.G Loan (£)  P.G Loan (£)  Total Loan (£)\n",
              "0  Idaline  19710427   50        F         24100         11900           36000\n",
              "1  Freddie  19621227   58        F         26600         12600           39200\n",
              "2    Debee  19701119   49        F         32400         97000           42100\n",
              "3   Joyann  19570124   41        T         24400         11500           35900\n",
              "4     Ajay  19600512   50        F         25500         18800           44300\n",
              "5   Emelia  19571123   57        T         34000         17500               0"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWiOtejRW5rO"
      },
      "source": [
        "Let's work on the **Age** variable first. According to our data documentation, the age in the field should reflect the current age of the loan holders. The exception to this is when the loan holder is deceased, in which case the age should contain the loan holder's age at the time of their passing. Let's first work out which rows break this condition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtfZWHhYW5rW",
        "outputId": "4cbe822a-806d-4af0-e8c2-e0debac9bd32"
      },
      "source": [
        "# Before we attempt this, we'll rename the rows to something that's easier to work with\n",
        "html_df.columns = [\"name\", \"dob\", \"age\", \"deceased\", \"ug_loan\", \"pg_loan\", \"total_loan\"]\n",
        "html_df.info()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6 entries, 0 to 5\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   name        6 non-null      object\n",
            " 1   dob         6 non-null      int64 \n",
            " 2   age         6 non-null      int64 \n",
            " 3   deceased    6 non-null      object\n",
            " 4   ug_loan     6 non-null      int64 \n",
            " 5   pg_loan     6 non-null      int64 \n",
            " 6   total_loan  6 non-null      int64 \n",
            "dtypes: int64(5), object(2)\n",
            "memory usage: 464.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "9zwwQKrpW5rX",
        "outputId": "64e55eac-c0bf-4841-9d37-2c7ce782edc3"
      },
      "source": [
        "## Convert 'dob' into a date object\n",
        "html_df['dob'] = pd.to_datetime(html_df['dob'], format=\"%Y%m%d\")\n",
        "html_df"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>dob</th>\n",
              "      <th>age</th>\n",
              "      <th>deceased</th>\n",
              "      <th>ug_loan</th>\n",
              "      <th>pg_loan</th>\n",
              "      <th>total_loan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Idaline</td>\n",
              "      <td>1971-04-27</td>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "      <td>24100</td>\n",
              "      <td>11900</td>\n",
              "      <td>36000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Freddie</td>\n",
              "      <td>1962-12-27</td>\n",
              "      <td>58</td>\n",
              "      <td>F</td>\n",
              "      <td>26600</td>\n",
              "      <td>12600</td>\n",
              "      <td>39200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Debee</td>\n",
              "      <td>1970-11-19</td>\n",
              "      <td>49</td>\n",
              "      <td>F</td>\n",
              "      <td>32400</td>\n",
              "      <td>97000</td>\n",
              "      <td>42100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Joyann</td>\n",
              "      <td>1957-01-24</td>\n",
              "      <td>41</td>\n",
              "      <td>T</td>\n",
              "      <td>24400</td>\n",
              "      <td>11500</td>\n",
              "      <td>35900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ajay</td>\n",
              "      <td>1960-05-12</td>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "      <td>25500</td>\n",
              "      <td>18800</td>\n",
              "      <td>44300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Emelia</td>\n",
              "      <td>1957-11-23</td>\n",
              "      <td>57</td>\n",
              "      <td>T</td>\n",
              "      <td>34000</td>\n",
              "      <td>17500</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      name        dob  age deceased  ug_loan  pg_loan  total_loan\n",
              "0  Idaline 1971-04-27   50        F    24100    11900       36000\n",
              "1  Freddie 1962-12-27   58        F    26600    12600       39200\n",
              "2    Debee 1970-11-19   49        F    32400    97000       42100\n",
              "3   Joyann 1957-01-24   41        T    24400    11500       35900\n",
              "4     Ajay 1960-05-12   50        F    25500    18800       44300\n",
              "5   Emelia 1957-11-23   57        T    34000    17500           0"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "0MkxtUXkW5rX",
        "outputId": "1903c26f-d406-4906-c1ac-0e7a3be1857d"
      },
      "source": [
        "html_df[\"now_date\"] "
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'now_date'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-9d54f442db0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhtml_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"now_date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'now_date'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RLBuT2IW5rZ",
        "outputId": "e8332a6d-d1b8-4aa3-e508-ad0e7937d957"
      },
      "source": [
        "pd.datetime.now()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.datetime(2021, 10, 9, 21, 38, 40, 508285)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0QdbLODW5rZ",
        "outputId": "ed6405df-5cce-496a-d6f9-6f19c0616226"
      },
      "source": [
        "# Creates a new column 'now_date' populated with the now datetime\n",
        "html_df[\"now_date\"] = pd.Timestamp(pd.datetime.now())\n",
        "\n",
        "## Calculate the difference between the 'dob' and 'now_date' and return the value as years\n",
        "now_date_dob_difference = html_df[\"now_date\"] - html_df['dob']\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWpGDmNyW5rb",
        "outputId": "7ae2a4e1-9b5d-455f-df12-cda30391d76f"
      },
      "source": [
        "now_date_dob_difference"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0   18428 days 21:38:55.889900\n",
              "1   21471 days 21:38:55.889900\n",
              "2   18587 days 21:38:55.889900\n",
              "3   23634 days 21:38:55.889900\n",
              "4   22430 days 21:38:55.889900\n",
              "5   23331 days 21:38:55.889900\n",
              "dtype: timedelta64[ns]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS61eBy-W5rc",
        "outputId": "711a8983-b7d7-4b73-a76c-9fef9cf2fe2f"
      },
      "source": [
        "np.timedelta64(1, 'Y')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.timedelta64(1,'Y')"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJdeP-I1W5rc",
        "outputId": "5050e1f8-9b1d-443e-9fbc-d684029ff076"
      },
      "source": [
        "import numpy as np\n",
        "# This line changes the the timedelta objects to a floating point year, which we then convert to an int\n",
        "now_date_dob_difference = (now_date_dob_difference / np.timedelta64(1, 'Y')).astype(\"int64\")\n",
        "now_date_dob_difference"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    50\n",
              "1    58\n",
              "2    50\n",
              "3    64\n",
              "4    61\n",
              "5    63\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM5VTnL5W5rd",
        "outputId": "cafca5af-4175-4145-b4cc-eabdd5a627d4"
      },
      "source": [
        "now_date_dob_difference"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    50\n",
              "1    58\n",
              "2    50\n",
              "3    64\n",
              "4    61\n",
              "5    63\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFHSDSmcW5re"
      },
      "source": [
        "# By eye, we can see which ages do not match the dataframe we showed previously. \n",
        "# For generality however, let's code this up with pandas logic.\n",
        "## Return rows where 'now_date_dob_difference' is different to the dataframe's age variable\n",
        "is_diff = now_date_dob_difference != html_df[\"age\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "mkWFi7GFW5rf",
        "outputId": "52f777d0-e1e7-4c92-96d9-09901aebfbd3"
      },
      "source": [
        "is_diff"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-a62fa753a1d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mis_diff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'is_diff' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "KIcf0NGTW5rf",
        "outputId": "2bad6459-49e3-4301-ccb6-93176e6b0653"
      },
      "source": [
        "html_df[is_diff]"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-70f20958d1bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhtml_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_diff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'is_diff' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZHdFSn1W5rg"
      },
      "source": [
        "Let's take a look into why the above cell's were returned. As mentioned previously, if a loan holder is deceased, then their age should reflect that. So this means that Joyann's and Emelia's age is actually correct. Using boolean logic, let's filter out these rows to return only the rows which have mathematically incorrect ages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "i4vt_UCFW5rg",
        "outputId": "e4dde919-a1fd-4d9b-efa9-1aad47880e5e"
      },
      "source": [
        "## Filter out the relevant loan holders using boolean logic (hint: &)\n",
        "incorrect_age_rows = html_df[(html_df[\"age\"] != now_date_dob_difference) & (html_df[\"deceased\"] == \"F\")]\n",
        "incorrect_age_rows"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>dob</th>\n",
              "      <th>age</th>\n",
              "      <th>deceased</th>\n",
              "      <th>ug_loan</th>\n",
              "      <th>pg_loan</th>\n",
              "      <th>total_loan</th>\n",
              "      <th>now_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Debee</td>\n",
              "      <td>1970-11-19</td>\n",
              "      <td>49</td>\n",
              "      <td>F</td>\n",
              "      <td>32400</td>\n",
              "      <td>97000</td>\n",
              "      <td>42100</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ajay</td>\n",
              "      <td>1960-05-12</td>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "      <td>25500</td>\n",
              "      <td>18800</td>\n",
              "      <td>44300</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    name        dob  age deceased  ug_loan  pg_loan  total_loan  \\\n",
              "2  Debee 1970-11-19   49        F    32400    97000       42100   \n",
              "4   Ajay 1960-05-12   50        F    25500    18800       44300   \n",
              "\n",
              "                    now_date  \n",
              "2 2021-10-09 21:38:55.889900  \n",
              "4 2021-10-09 21:38:55.889900  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "JqsVvQvkW5rg",
        "outputId": "98ff7edb-8a80-438c-e0dc-12ae25e71b05"
      },
      "source": [
        "## Update incorrect_age_rows dataframe with the corrected ages\n",
        "incorrect_age_rows[\"age\"] = ((incorrect_age_rows[\"now_date\"] - incorrect_age_rows[\"dob\"]) / np.timedelta64(1, 'Y')).astype(\"int64\")\n",
        "incorrect_age_rows"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>dob</th>\n",
              "      <th>age</th>\n",
              "      <th>deceased</th>\n",
              "      <th>ug_loan</th>\n",
              "      <th>pg_loan</th>\n",
              "      <th>total_loan</th>\n",
              "      <th>now_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Debee</td>\n",
              "      <td>1970-11-19</td>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "      <td>32400</td>\n",
              "      <td>97000</td>\n",
              "      <td>42100</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ajay</td>\n",
              "      <td>1960-05-12</td>\n",
              "      <td>61</td>\n",
              "      <td>F</td>\n",
              "      <td>25500</td>\n",
              "      <td>18800</td>\n",
              "      <td>44300</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    name        dob  age deceased  ug_loan  pg_loan  total_loan  \\\n",
              "2  Debee 1970-11-19   50        F    32400    97000       42100   \n",
              "4   Ajay 1960-05-12   61        F    25500    18800       44300   \n",
              "\n",
              "                    now_date  \n",
              "2 2021-10-09 21:38:55.889900  \n",
              "4 2021-10-09 21:38:55.889900  "
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBytKNz6W5rh"
      },
      "source": [
        "## Now update the relevant entries html_df with the age column from the incorrect_age_rows dataframe\n",
        "html_df.update(incorrect_age_rows[\"age\"])\n",
        "html_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KsRSfafW5rh"
      },
      "source": [
        "## Convert age back to an int\n",
        "html_df[\"age\"] = html_df[\"age\"].astype(\"int64\")\n",
        "## Drop the now_date column\n",
        "html_df.drop([\"now_date\"], axis=1, inplace=True)\n",
        "html_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2Xe__zrW5ri"
      },
      "source": [
        "Let's work on the loan amounts now. Return all the columns where `ug_loan` + `pg_loan` is not equal to `total_loan`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x0uYpBiW5ri"
      },
      "source": [
        "## Subset `ug_loan` and `pg_loan` from our dataframe, and then sum along the column axis\n",
        "sum_loans = html_df[[\"ug_loan\", \"pg_loan\"]].sum(axis=1)\n",
        "html_df['computed'] = sum_loans"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "yQeqY07AW5rj",
        "outputId": "2a624214-9d3f-40bf-c38b-9c0f468afa30"
      },
      "source": [
        "# html_df[\"pg_loan\"].describe()\n",
        "html_df[html_df[\"pg_loan\"] == html_df[\"pg_loan\"].max()]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>dob</th>\n",
              "      <th>age</th>\n",
              "      <th>deceased</th>\n",
              "      <th>ug_loan</th>\n",
              "      <th>pg_loan</th>\n",
              "      <th>total_loan</th>\n",
              "      <th>now_date</th>\n",
              "      <th>computed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Debee</td>\n",
              "      <td>1970-11-19</td>\n",
              "      <td>49</td>\n",
              "      <td>F</td>\n",
              "      <td>32400</td>\n",
              "      <td>97000</td>\n",
              "      <td>42100</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "      <td>129400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    name        dob  age deceased  ug_loan  pg_loan  total_loan  \\\n",
              "2  Debee 1970-11-19   49        F    32400    97000       42100   \n",
              "\n",
              "                    now_date  computed  \n",
              "2 2021-10-09 21:38:55.889900    129400  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sBZN2ItrW5rk",
        "outputId": "5e2a9e4e-efc1-49a9-c2d7-007c35485b25"
      },
      "source": [
        "html_df.drop(2, axis=0)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>dob</th>\n",
              "      <th>age</th>\n",
              "      <th>deceased</th>\n",
              "      <th>ug_loan</th>\n",
              "      <th>pg_loan</th>\n",
              "      <th>total_loan</th>\n",
              "      <th>now_date</th>\n",
              "      <th>computed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Idaline</td>\n",
              "      <td>1971-04-27</td>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "      <td>24100</td>\n",
              "      <td>11900</td>\n",
              "      <td>36000</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "      <td>36000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Freddie</td>\n",
              "      <td>1962-12-27</td>\n",
              "      <td>58</td>\n",
              "      <td>F</td>\n",
              "      <td>26600</td>\n",
              "      <td>12600</td>\n",
              "      <td>39200</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "      <td>39200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Joyann</td>\n",
              "      <td>1957-01-24</td>\n",
              "      <td>41</td>\n",
              "      <td>T</td>\n",
              "      <td>24400</td>\n",
              "      <td>11500</td>\n",
              "      <td>35900</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "      <td>35900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ajay</td>\n",
              "      <td>1960-05-12</td>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "      <td>25500</td>\n",
              "      <td>18800</td>\n",
              "      <td>44300</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "      <td>44300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Emelia</td>\n",
              "      <td>1957-11-23</td>\n",
              "      <td>57</td>\n",
              "      <td>T</td>\n",
              "      <td>34000</td>\n",
              "      <td>17500</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "      <td>51500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      name        dob  age deceased  ug_loan  pg_loan  total_loan  \\\n",
              "0  Idaline 1971-04-27   50        F    24100    11900       36000   \n",
              "1  Freddie 1962-12-27   58        F    26600    12600       39200   \n",
              "3   Joyann 1957-01-24   41        T    24400    11500       35900   \n",
              "4     Ajay 1960-05-12   50        F    25500    18800       44300   \n",
              "5   Emelia 1957-11-23   57        T    34000    17500           0   \n",
              "\n",
              "                    now_date  computed  \n",
              "0 2021-10-09 21:38:55.889900     36000  \n",
              "1 2021-10-09 21:38:55.889900     39200  \n",
              "3 2021-10-09 21:38:55.889900     35900  \n",
              "4 2021-10-09 21:38:55.889900     44300  \n",
              "5 2021-10-09 21:38:55.889900     51500  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "XvNnJ2NPW5rl",
        "outputId": "a3d8dcbf-cf5d-4092-9ed6-b3098315bdcd"
      },
      "source": [
        "## Return the rows which have incorrect sum values\n",
        "incorrect_loan_rows = html_df[html_df[\"total_loan\"] != sum_loans]\n",
        "incorrect_loan_rows"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>dob</th>\n",
              "      <th>age</th>\n",
              "      <th>deceased</th>\n",
              "      <th>ug_loan</th>\n",
              "      <th>pg_loan</th>\n",
              "      <th>total_loan</th>\n",
              "      <th>now_date</th>\n",
              "      <th>computed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Debee</td>\n",
              "      <td>1970-11-19</td>\n",
              "      <td>49</td>\n",
              "      <td>F</td>\n",
              "      <td>32400</td>\n",
              "      <td>97000</td>\n",
              "      <td>42100</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "      <td>129400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Emelia</td>\n",
              "      <td>1957-11-23</td>\n",
              "      <td>57</td>\n",
              "      <td>T</td>\n",
              "      <td>34000</td>\n",
              "      <td>17500</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "      <td>51500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     name        dob  age deceased  ug_loan  pg_loan  total_loan  \\\n",
              "2   Debee 1970-11-19   49        F    32400    97000       42100   \n",
              "5  Emelia 1957-11-23   57        T    34000    17500           0   \n",
              "\n",
              "                    now_date  computed  \n",
              "2 2021-10-09 21:38:55.889900    129400  \n",
              "5 2021-10-09 21:38:55.889900     51500  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "137JWhLsW5rq"
      },
      "source": [
        "### How should we deal with fields which fail validation?\n",
        "\n",
        "Here we see two rows which don't have the correct total loan amounts. Analysing each one individually, we see that the first row's data has most likely had the `pg_loan` value entered incorrectly (£97,000 for a postgraduate loan). In the second, for some reason the `total_loan` value has not been calculated. A naive strategy could be to overwrite the whole total loan amounts with the summation of `ug_loan` and `pg_loan`. This fixes the types of error on which the second row is returned. However there could be an underlying issue because of the first row. If we sum the `ug_loan` and `pg_loan` here, we will create an **outlier** (these will be covered in detail later). In a real dataset, it is a very real threat mistakes like these could occur which compromise the integrity of the data - issues like these can easily slip the mind so make sure you take the time to think through how your actions are going to affect your data.\n",
        "\n",
        "As I mentioned, some aspects of data science are an art - but whatever heuristic decision we make, we have to find a strong justifcation for it. In this particular case, I am going to drop the rows with the incorrect `total_loan` as this error probably occured due to a mistake in human data entry. The rows with `total_loan = 0` probably occured due to some systematic error - perhaps from from some other database where the total_loan amount wasn't present. Other checks considering, one solution we could opt for is to sum the two columns together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "MtmTVM8fW5rq",
        "outputId": "f54010f8-641d-4c73-add0-95e58505a21d"
      },
      "source": [
        "## Identify the rows where total_loan is NOT 0, but is incorrect\n",
        "incorrect_loan_but_not_zero_rows = html_df[(html_df[\"total_loan\"] != sum_loans) & (html_df[\"total_loan\"] != 0)]\n",
        "print(incorrect_loan_but_not_zero_rows)\n",
        "\n",
        "## Drop these rows from the original dataframe\n",
        "html_df = html_df.drop(incorrect_loan_but_not_zero_rows.index)\n",
        "\n",
        "html_df"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    name        dob  age deceased  ug_loan  pg_loan  total_loan  \\\n",
            "2  Debee 1970-11-19   49        F    32400    97000       42100   \n",
            "\n",
            "                    now_date  computed  \n",
            "2 2021-10-09 21:38:55.889900    129400  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>dob</th>\n",
              "      <th>age</th>\n",
              "      <th>deceased</th>\n",
              "      <th>ug_loan</th>\n",
              "      <th>pg_loan</th>\n",
              "      <th>total_loan</th>\n",
              "      <th>now_date</th>\n",
              "      <th>computed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Idaline</td>\n",
              "      <td>1971-04-27</td>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "      <td>24100</td>\n",
              "      <td>11900</td>\n",
              "      <td>36000</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "      <td>36000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Freddie</td>\n",
              "      <td>1962-12-27</td>\n",
              "      <td>58</td>\n",
              "      <td>F</td>\n",
              "      <td>26600</td>\n",
              "      <td>12600</td>\n",
              "      <td>39200</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "      <td>39200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Joyann</td>\n",
              "      <td>1957-01-24</td>\n",
              "      <td>41</td>\n",
              "      <td>T</td>\n",
              "      <td>24400</td>\n",
              "      <td>11500</td>\n",
              "      <td>35900</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "      <td>35900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ajay</td>\n",
              "      <td>1960-05-12</td>\n",
              "      <td>50</td>\n",
              "      <td>F</td>\n",
              "      <td>25500</td>\n",
              "      <td>18800</td>\n",
              "      <td>44300</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "      <td>44300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Emelia</td>\n",
              "      <td>1957-11-23</td>\n",
              "      <td>57</td>\n",
              "      <td>T</td>\n",
              "      <td>34000</td>\n",
              "      <td>17500</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-10-09 21:38:55.889900</td>\n",
              "      <td>51500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      name        dob  age deceased  ug_loan  pg_loan  total_loan  \\\n",
              "0  Idaline 1971-04-27   50        F    24100    11900       36000   \n",
              "1  Freddie 1962-12-27   58        F    26600    12600       39200   \n",
              "3   Joyann 1957-01-24   41        T    24400    11500       35900   \n",
              "4     Ajay 1960-05-12   50        F    25500    18800       44300   \n",
              "5   Emelia 1957-11-23   57        T    34000    17500           0   \n",
              "\n",
              "                    now_date  computed  \n",
              "0 2021-10-09 21:38:55.889900     36000  \n",
              "1 2021-10-09 21:38:55.889900     39200  \n",
              "3 2021-10-09 21:38:55.889900     35900  \n",
              "4 2021-10-09 21:38:55.889900     44300  \n",
              "5 2021-10-09 21:38:55.889900     51500  "
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuxdFBp0W5rr"
      },
      "source": [
        "# Assuming that all we're happy with all the other entries in our loan holders, we can directly compute and overwrite total_loan in our dataframe\n",
        "## Overwrite total_loan with the sum of ug_loan and pg_loan\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVINujpMW5rr"
      },
      "source": [
        "## Working with text data and strings\n",
        "\n",
        "Text data is obviously an extremely common type of data, and it can take on many forms - ranging from free unstructured text to emails, names, phone numbers etc. There are many types of problems we can encounter with text data:\n",
        "- Data inconsistency (e.g. \t+86 195 448 8582 vs 0086-195-448-8582)\n",
        "- Text violations (e.g. illegal characters, input field errors, text typos)\n",
        "- \"Structured\" typos (e.g. +86.1954.48858.2)\n",
        "\n",
        "In the example table below, we see a list of people with their names and phone numbers. As seen - most likely due to free text fields, the names and phone numbers have been entered in a variety of different formats. Our job is to standardise these fields so they're consistent throughout the dataframe:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><b>Name</b></td>\n",
        "        <td><b>Phone Number</b></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Dr Darci Abela</td>\n",
        "        <td>+86-185-338-1819</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Mr Patten St. Queintain</td>\n",
        "        <td>00865872411917</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>mr conant burden</td>\n",
        "        <td>0086-289-702-0948</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>miss marcia Dutnell</td>\n",
        "        <td>0668</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>dr Greggory lurner</td>\n",
        "        <td>+31 778 813 8432</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>MS Doe Beavan</td>\n",
        "        <td>+420-731-276-7633</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Tamarah Delgado</td>\n",
        "        <td>+868431029051</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Miss Arlee daborne</td>\n",
        "        <td>+33-307-220-2746</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>Ly b. Grima</td>\n",
        "        <td>+238-863-946-4232</td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "I have created a small dummy csv we can work with for this task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "egO7Xbz_W5rr",
        "outputId": "84f2d8fe-0b82-44ff-be0c-72be04ab401f"
      },
      "source": [
        "# np = names_phones\n",
        "np_df = pd.read_csv(\"../DATA/mock_names_phones.csv\", header=0, index_col=0)\n",
        "np_df"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-6144297c60c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# np = names_phones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../DATA/mock_names_phones.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnp_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../DATA/mock_names_phones.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DndZzyQFW5rs"
      },
      "source": [
        "Ok - there are 4 tasks for this dataframe:\n",
        "1. Create a 'title' column which contains each individual's title (e.g. Mrs, Miss etc). This column should be standardized and categorical\n",
        "2. Split the actual name into a first name and last name column. Both columns should have a capital letter for the first letter of the name\n",
        "3. Drop the `name` row\n",
        "4. Standardise the phone numbers with the format `00XXXXXXXXX`. That is - two zeros prepended to the rest of the actual number\n",
        "\n",
        "Let's tackle these in order"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfXIZyiQW5rs",
        "outputId": "d202a52b-81a9-408a-fb8f-536e04575ca2"
      },
      "source": [
        "# First, we want to create a new title column which takes on the honourifics in the name column\n",
        "# To obtain this, we have to split the name on whitespace and take the first element from the split list\n",
        "example_string = \"This string will be split\"\n",
        "print(example_string.split())\n",
        "print(example_string.split()[0])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'string', 'will', 'be', 'split']\n",
            "This\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "Qh4QY7qsW5rs",
        "outputId": "1cc549f7-c09c-49d8-9dea-d29f5687208f"
      },
      "source": [
        "# To perform some string operations on string columns in pandas, we need to prepend our string function with '.str'\n",
        "np_df[\"name\"].str.split()\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-e432d7aa842e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# To perform some string operations on string columns in pandas, we need to prepend our string function with '.str'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbNzgh8vW5rs"
      },
      "source": [
        "## Create and populate a title column.\n",
        "# This task can be solved in a couple of different ways.\n",
        "# See how many solutions you can come up with in your groups\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85f9vrFDW5rs"
      },
      "source": [
        "# We want our title to be standardised and categorical.\n",
        "## Convert the column to a categorical column and return all the categories that currently exist in the column\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixkxoh7AW5rt"
      },
      "source": [
        "# We see many different variants. Let's select a method to normalise the entries (e.g. uppercase all).\n",
        "## Standardise the title column\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMSnQNvCW5rt"
      },
      "source": [
        "## In somewhat of a similar fashion to the above, create a new column for first name and one for last name.\n",
        "# Ensure for both new columns, the names are in lower case form, apart from the first letter which is upper cased\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5ChUtODW5rt"
      },
      "source": [
        "## Drop the name column\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaA1bL8LW5ru"
      },
      "source": [
        "Great! This brings us up to the 4th part of the tasks - standardising the phone number and converting them to an int datatype. Recall how we want our phone numbers to look after: start with 00, followed by the rest of the number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jVru5gc7W5ru"
      },
      "source": [
        "# Returns all the (unique) phone numbers so we can see the different types of issues they contain\n",
        "set(np_df[\"phone number\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raHDbBifW5ru"
      },
      "source": [
        "Ok, so what issues do you see?\n",
        "<details>\n",
        "    <summary><b>> Click here to see issues</b></summary>\n",
        "    <ul>\n",
        "        <li>Numbers start differently - some start with `+`, others with `00`</li>\n",
        "        <li>Some numbers have spaces between a group of numbers, others are hyphenated. Some of the numbers don't have 'groups' either</li>\n",
        "        <li>Some numbers start with a whitespace, others with a `+ `, others with a `+  `.</li>\n",
        "        <li>Some numbers are only four numbers long</li>\n",
        "    </ul>\n",
        "</details>\n",
        "\n",
        "There are a couple of ways we could go about formatting these strings into our desired output. Here I will guide you through a method where we iterate through the rows and apply a function to reassign the variable. Let's start by creating an intermediate function which takes a phone number and manipulates it to our desired output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaD5h1sGW5rv"
      },
      "source": [
        "def standardise_phone_number(phone_number):\n",
        "    \n",
        "    ## if the first character is a \"+\", remove it.\n",
        "    \n",
        "    ## remove all whitespace from the phone number\n",
        "    \n",
        "    ## remove hyphens from the phone number\n",
        "    \n",
        "    ## if the number doesn't start with 00, prepend 00 to it beginning of the number\n",
        "    \n",
        "    ## return the phone number\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxb48v6mW5rw"
      },
      "source": [
        "# We'll iterate over the rows of the dataframe, and reassign the row to the standardised variant\n",
        "for index, row in np_df.iterrows():\n",
        "    \n",
        "    ## Call our standardisation function on the phone number for the current loop\n",
        "    \n",
        "np_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yfGQlXZW5rx"
      },
      "source": [
        "# We still have some invalid numbers in our dataframe (i.e. those which were originally of length 4)\n",
        "## Replace all phone numbers under 10 numbers/characters long with pd.NA\n",
        "# Hint: The .loc method will be needed\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7KTz-FFW5rz"
      },
      "source": [
        "# We'll be focusing on missing data in the next section, but let's count the number of rows with NA's in them and drop them too\n",
        "null_phone_numbers = np_df[\"phone number\"].isnull()\n",
        "print(\"Number of null phone numbers:\", null_phone_numbers.sum())\n",
        "\n",
        "# Drop the rows which have null phone numbers\n",
        "np_df = np_df.dropna(subset=[\"phone number\"])\n",
        "np_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgSIawXOW5r1"
      },
      "source": [
        "More complicated string manipulations can be performed via the use of **Regular Expressions**, otherwise known as [regex](https://docs.python.org/3/howto/regex.html). We won't look at regex here but it's important to know about it's power. Essentially, regex allows us to specify rules for strings that we want to match against. It has a very wide application usecase. Some examples include:\n",
        "- indentify emails in spans of text \n",
        "- validate whether a url has a correct format\n",
        "- extract only the digits from a text string\n",
        "\n",
        "When you come across tasks which non-trivially require you to clean text data, regex is the tool for the job. "
      ]
    }
  ]
}